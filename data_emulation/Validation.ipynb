{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61c0a20-fc05-492c-9cd7-3ce7d097a31b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of CUDA Devices: 1\n",
      "CUDA Device 0: NVIDIA A100-PCIE-40GB MIG 2g.10gb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import signal, sparse\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch import einsum\n",
    "\n",
    "\n",
    "home_dir='/nas/longleaf/home/kbhimani/'\n",
    "scratch_dir = '/work/users/k/b/kbhimani/'\n",
    "eng_peak='fep' # training peak\n",
    "os.chdir(home_dir+'/CPU-Net')\n",
    "\n",
    "\n",
    "\n",
    "# Loading CPU-Net and support functions\n",
    "from tools import (calc_current_amplitude, process_all_waveforms, calculate_tn, check_peak_alignment,\n",
    "                   get_tail_slope, inf_train_gen, LambdaLR, weights_init_normal, select_quantile, calculate_iou)\n",
    "from dataset import SplinterDataset, SEQ_LEN, LSPAN, RSPAN\n",
    "from network import PositionalUNet, RNN\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# Print whether CUDA is available or not\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "# If CUDA is available, print the CUDA device count and device name(s)\n",
    "if cuda_available:\n",
    "    print(f\"Number of CUDA Devices: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"CUDA Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3953fbb7-d244-4935-822f-1667eba42332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 32 # batch size, each batch is drawn from the infinite train generator\n",
    "# baseline_len = 200 # number of samples assigned to baseline portions\n",
    "# rising_edge_len = 250 # number of samples assigned to rising edge\n",
    "# tail_len = 350 # number of samples assigned to tail \n",
    "# baseline_weight=3.0 # weight given to baseline portion of the waveform in loss function\n",
    "# ris_edge_weight=10.0 # weight giveing to rising edge of the waveform in loss function\n",
    "# tail_weight=7.0 # weight giving to the RC decay tail of the wavefrom in loss function\n",
    "# ITERS = 5000 # max number of interations to run\n",
    "# DECAY = 2500 # iteration at which learning rate starts to decay\n",
    "# LRATE_Gen =1e-2 # learning rate of the generator\n",
    "# LRATE_Disc =1e-3 # learning rate of the discriminator\n",
    "# cyc_loss_weight = 10 # weight of the cycle consistent loss in training, eg loss(sim->data->sim)\n",
    "# iden_loss_weight = 5 # weight of idenentity loss, for example ATN(data)- data\n",
    "# gan_loss_weight = 1 # weight of the generator loss. ATN(sim) - data\n",
    "# max_grad_norm = 40 # Maximum norm for gradient clipping\n",
    "# w_decay = 1e-3 # weight decay in the optimizers\n",
    "# n_disc_iters = 25  # Set the number of iterations after which discriminators will be updated\n",
    "# max_sample = 2e4 # numbers of samples to used for training\n",
    "BATCH_SIZE = 32 # batch size, each batch is drawn from the infinite train generator\n",
    "baseline_len = 200 # number of samples assigned to baseline portions\n",
    "rising_edge_len = 250 # number of samples assigned to rising edge\n",
    "tail_len = 350 # number of samples assigned to tail \n",
    "baseline_weight=3.0 # weight given to baseline portion of the waveform in loss function\n",
    "ris_edge_weight=10.0 # weight giveing to rising edge of the waveform in loss function\n",
    "tail_weight=7.0 # weight giving to the RC decay tail of the wavefrom in loss function\n",
    "ITERS = 7000 # max number of interations to run\n",
    "DECAY = 2500 # iteration at which learning rate starts to decay\n",
    "LRATE_Gen =1e-2 # learning rate of the generator\n",
    "LRATE_Disc =1e-3 # learning rate of the discriminator\n",
    "cyc_loss_weight = 10 # weight of the cycle consistent loss in training, eg loss(sim->data->sim)\n",
    "iden_loss_weight = 5 # weight of idenentity loss, for example ATN(data)- data\n",
    "gan_loss_weight = 1 # weight of the generator loss. ATN(sim) - data\n",
    "max_grad_norm = 40 # Maximum norm for gradient clipping\n",
    "w_decay = 1e-3 # weight decay in the optimizers\n",
    "n_disc_iters = 25  # Set the number of iterations after which discriminators will be updated\n",
    "max_sample = 2e4 # numbers of samples to used for training\n",
    "# Check if DECAY is less than ITERS\n",
    "if DECAY >= ITERS:\n",
    "    raise ValueError(\"DECAY must be less than ITERS to avoid division by zero in the learning rate scheduler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10a2c4f-968c-40d2-8ace-fb6a1661bef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sim_pulses = scratch_dir+f'cpu_net_datasets/{eng_peak}_sim_noise_pz.pkl'\n",
    "# det_pulses = scratch_dir+f'cpu_net_datasets/{eng_peak}_sim_preamp_noise_pz.pkl'\n",
    "sim_pulses = scratch_dir+f'cpu_net_datasets/{eng_peak}_sim_pz.pkl'\n",
    "det_pulses = scratch_dir+f'cpu_net_datasets/{eng_peak}_sim_preamp_pz.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305484da-6cb0-4d6d-8348-89b62c2e1754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch.utils.data as data_utils\n",
    "# import torch.nn as nn\n",
    "# import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "# from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "# from tools import calculate_tn\n",
    "# from tqdm import tqdm\n",
    "# import random\n",
    "# from scipy.optimize import curve_fit\n",
    "\n",
    "# '''\n",
    "# Parameters for training waveform construction.\n",
    "# LSPAN: how many sample to select to the left of time point 0 (start of the rise)\n",
    "# RSPAN: how many sample to select to the right of time point 0 (start of the rise)\n",
    "# SEQ_LEN: total length of the input pulses, always equal to LSPAN+RSPAN\n",
    "# '''\n",
    "# LSPAN=300\n",
    "# RSPAN=500\n",
    "# SEQ_LEN=LSPAN+RSPAN\n",
    "# t_n = 99.9\n",
    "# base_thres = 0.005 # mean of first 50 smaples should be less than this value\n",
    "# tail_thres = 0.80 # last 50 samples should be greater than this value\n",
    "# # chi_squared_threshold= 0.002\n",
    "# # popt_threshold = -2.6e-4\n",
    "# norm_tail_height = 0.80\n",
    "# norm_samples = 5\n",
    "# class SplinterDataset(Dataset):\n",
    "#     '''\n",
    "#     Splinter is the name of our local Ge detector\n",
    "#     '''\n",
    "#     def __init__(self, event_dset=\"DetectorPulses.pickle\", siggen_dset=\"SimulatedPulses.pickle\", n_max=1e7, chi_squared_threshold=1, popt_threshold_under=-2, popt_threshold_over=2):\n",
    "#         self.n_max = n_max\n",
    "#         self.chi_squared_threshold = chi_squared_threshold\n",
    "#         self.popt_threshold_over = popt_threshold_over\n",
    "#         self.popt_threshold_under = popt_threshold_under\n",
    "#         self.chi_squared_coeff = []\n",
    "#         self.tau_fits = []\n",
    "        \n",
    "#         # Load data and simulation waveforms synchronously\n",
    "#         self.event_dict, self.siggen_dict = self.event_loader_synchronized(event_dset, siggen_dset)\n",
    "#         print(\"Number of Data events:\", len(self.event_dict))\n",
    "#         print(\"Number of Simulation events:\", len(self.siggen_dict))\n",
    "\n",
    "#         # Set the class attributes for thresholds here\n",
    "#         self.size = min(len(self.event_dict), len(self.siggen_dict))\n",
    "#         self.event_ids = [wdict[\"event\"] for wdict in self.siggen_dict]\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         # Return the minimum size between event_dict and siggen_dict to avoid out-of-range errors\n",
    "#         return min(len(self.event_dict), len(self.siggen_dict))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         # Use a single simulated waveform based on the index and transform it\n",
    "#         siggenwf = self.transform(self.siggen_dict[idx][\"wf\"], self.siggen_dict[idx][\"tp0\"], sim=True)\n",
    "#         # Transform the real waveform for comparison or any other purpose\n",
    "#         real_wf = self.transform(self.event_dict[idx][\"wf\"], self.event_dict[idx][\"tp0\"])\n",
    "#         # Return the real waveform, the single transformed simulated waveform, and the original waveform\n",
    "#         event_id = self.siggen_dict[idx].get(\"event\", -1)  # Default to -1 or suitable value if not found\n",
    "#         # Return the event_id as part of the output\n",
    "#         return real_wf[None, :], siggenwf[None, :], self.event_dict[idx], self.event_dict[idx]\n",
    "        \n",
    "#     def return_label(self):\n",
    "#         return self.trainY\n",
    "    \n",
    "#     def set_raw_waveform(self,raw_wf):\n",
    "#         self.raw_waveform = raw_wf\n",
    "\n",
    "#     def get_original_waveform(self,wf, input=False):\n",
    "#         if input:\n",
    "#             return self.input_transform.recon_waveform(wf)\n",
    "#         else:\n",
    "#             return self.output_transform.recon_waveform(wf)\n",
    "        \n",
    "\n",
    "\n",
    "#     def normalize_waveform(self, wf):\n",
    "#         \"\"\"Normalize waveform to have values between 0 and 1.\"\"\"\n",
    "#         min_val = np.min(wf)\n",
    "#         max_val = np.max(wf)\n",
    "#         if max_val > min_val:\n",
    "#             return (wf - min_val) / (max_val - min_val)\n",
    "#         else:\n",
    "#             # Handle the case where max_val equals min_val (e.g., constant waveforms)\n",
    "#             return np.zeros_like(wf)  # or wf * 0 to return a waveform of zeros\n",
    "\n",
    "#     def transform(self, wf, tp0, sim=False):\n",
    "#         \"\"\"Transform waveform by padding based on tp0 and then normalizing.\"\"\"\n",
    "#         wf = np.array(wf)\n",
    "#         # Ensure tp0 is an integer\n",
    "#         tp0 = int(round(tp0))\n",
    "#         left_padding = max(LSPAN - tp0, 0)\n",
    "#         right_padding = max((RSPAN + tp0) - len(wf), 0)\n",
    "#         # Apply padding\n",
    "#         wf_padded = np.pad(wf, (left_padding, right_padding), mode='edge')\n",
    "#         # Adjust tp0 after padding\n",
    "#         tp0_adjusted = tp0 + left_padding\n",
    "#         # Slice the waveform around the adjusted tp0 to ensure consistent length\n",
    "#         wf_sliced = wf_padded[(tp0_adjusted - LSPAN):(tp0_adjusted + RSPAN)]\n",
    "#         # Normalize the waveform after padding and slicing\n",
    "#         wf_normalized = self.normalize_waveform(wf_sliced)\n",
    "#         # Don't normalize if it is sim as it is already normalized\n",
    "#         return wf_normalized\n",
    "\n",
    "#     def event_loader_synchronized(self, data_address, sim_address, elow=-99999, ehi=99999):\n",
    "#         data_wf_list = []\n",
    "#         sim_wf_list = []\n",
    "#         count = 0\n",
    "\n",
    "#         print(\"Chi squared cut is\", self.chi_squared_threshold)\n",
    "#         print(\"Tail slope cut over is\", self.popt_threshold_over)\n",
    "#         print(\"Tail slope cut under is\", self.popt_threshold_under)\n",
    "\n",
    "#         with open(data_address, \"rb\") as data_file, open(sim_address, \"rb\") as sim_file:\n",
    "#             while True:\n",
    "#                 if count > self.n_max:\n",
    "#                     break\n",
    "#                 try:\n",
    "#                     # Load both data and simulation waveforms\n",
    "#                     data_wdict = pickle.load(data_file, encoding='latin1')\n",
    "#                     sim_wdict = pickle.load(sim_file, encoding='latin1')\n",
    "\n",
    "#                     data_wf = data_wdict[\"wf\"]\n",
    "#                     sim_wf = sim_wdict[\"wf\"]\n",
    "                    \n",
    "                    \n",
    "#                     data_tp0 = 600 # we know this values for simulations, it same as the padding added\n",
    "#                     sim_tp0 = 600             \n",
    "\n",
    "#                     # Transform and check conditions for the data waveform\n",
    "#                     data_transformed_wf = self.transform(data_wf, data_tp0)\n",
    "#                     # if len(data_transformed_wf) != SEQ_LEN or np.any(data_transformed_wf[:250] > 0.025) or np.any(data_transformed_wf[-50:] < tail_thres):\n",
    "#                     #     continue  # Skip this pair if data does not meet criteria\n",
    "\n",
    "#                     # Transform the simulation waveform\n",
    "#                     sim_transformed_wf = self.transform(sim_wf, sim_tp0)\n",
    "                    \n",
    "#                     # if len(sim_transformed_wf) != SEQ_LEN or np.any(sim_transformed_wf[:250] > 0.025) or np.any(sim_transformed_wf[-50:] < tail_thres):\n",
    "#                     #     continue  # Skip this pair if sim does not meet criteria\n",
    "                        \n",
    "#                     # Append both waveforms if all conditions are met\n",
    "#                     data_wf_list.append(data_wdict)\n",
    "#                     sim_wf_list.append(sim_wdict)\n",
    "#                     count += 1\n",
    "\n",
    "#                     if count % 10000 == 0:\n",
    "#                         print(f\"{count} waveform pairs loaded.\")\n",
    "\n",
    "#                 except EOFError:\n",
    "#                     break\n",
    "\n",
    "#         return data_wf_list, sim_wf_list\n",
    "    \n",
    "#     def get_field_from_dict(self, input_dict, fieldname):\n",
    "#         field_list = []\n",
    "#         for event in input_dict:\n",
    "#             field_list.append(event[fieldname])\n",
    "#         return field_list\n",
    "    \n",
    "#     def get_current_amp(self,wf):\n",
    "#         return max(np.diff(wf.flatten()))\n",
    "    \n",
    "#     def plot_waveform(self):\n",
    "#         num_waveforms_to_plot = 200\n",
    "\n",
    "#         # Create the first figure for all data waveforms\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         for i in range(num_waveforms_to_plot):\n",
    "#             # Fetch the real waveform from the dataset\n",
    "#             real_wf, sim_wf, _, _ = self.__getitem__(i)\n",
    "#             # Plot the real data waveform on the figure\n",
    "#             plt.plot(real_wf[0], linewidth=0.5, label=f'Data Pulse {i+1}' if i < 1 else \"\")  # Add label only once for legend\n",
    "\n",
    "#         plt.title(f\"{num_waveforms_to_plot} Data Pulses\")\n",
    "#         plt.xlabel(\"Time Sample [ns]\")\n",
    "#         plt.ylabel(\"Amplitude\")\n",
    "#         plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#         plt.minorticks_on()\n",
    "#         plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "#         plt.legend(loc='upper right')\n",
    "#         plt.savefig('figs/all_data_pulses.png', dpi=200)\n",
    "#         plt.show()\n",
    "\n",
    "#         # Create the second figure for all simulated waveforms\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         for i in range(num_waveforms_to_plot):\n",
    "#             # Fetch the corresponding simulated waveform from the dataset\n",
    "#             real_wf, sim_wf, _, _ = self.__getitem__(i)\n",
    "#             # Plot the simulated waveform on the figure\n",
    "#             plt.plot(sim_wf[0], linewidth=0.5, label=f'Simulated Pulse {i+1}' if i < 1 else \"\")  # Add label only once for legend\n",
    "\n",
    "#         plt.title(f\"{num_waveforms_to_plot} Simulated Pulses\")\n",
    "#         plt.xlabel(\"Time Sample [ns]\")\n",
    "#         plt.ylabel(\"Amplitude\")\n",
    "#         plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#         plt.minorticks_on()\n",
    "#         plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "#         plt.legend(loc='upper right')\n",
    "#         plt.savefig('figs/all_simulated_pulses.png', dpi=200)\n",
    "#         plt.show()\n",
    "\n",
    "    \n",
    "#     def linear(self, x, a, b):\n",
    "#         \"\"\"Linear function ax + b\"\"\"\n",
    "#         return a * x + b\n",
    "    \n",
    "#     def process_wf_log_linear(self, wf):\n",
    "#         sample = 300\n",
    "#         if len(wf) < sample:\n",
    "#             # Return default values if waveform is too short\n",
    "#             return np.nan, [np.nan, np.nan]  # Ensure popt is a list or array to safely index [0] later\n",
    "#         x_data = np.arange(sample)\n",
    "#         y_data = np.log(np.clip(wf[-sample:], 1e-10, None))  # Log of last 300 samples\n",
    "#         try:\n",
    "#             popt, pcov = curve_fit(self.linear, x_data, y_data, maxfev=100000)\n",
    "#             # Calculate residuals and chi-squared for goodness of fit\n",
    "#             residuals = y_data - self.linear(x_data, *popt)\n",
    "#             chi_squared = np.sum((residuals ** 2) / self.linear(x_data, *popt))\n",
    "#         except Exception as e:\n",
    "#             # Handle fitting errors\n",
    "#             popt = [np.nan, np.nan]  # Ensure popt is a list or array\n",
    "#             chi_squared = np.nan\n",
    "#         return -chi_squared, popt[0] #chi squared would be negative since log of number between 0,1 is negavtive, so we return positive value  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753e156c-7b17-4f50-a520-c3fc5085f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from tools import calculate_tn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Parameters for training waveform construction\n",
    "LSPAN = 400\n",
    "RSPAN = 400\n",
    "SEQ_LEN = LSPAN + RSPAN\n",
    "t_n = 99.9\n",
    "base_thres = 0.005  # mean of first 50 samples should be less than this value\n",
    "tail_thres = 0.78  # last 50 samples should be greater than this value\n",
    "norm_tail_height = 0.80\n",
    "norm_samples = 5\n",
    "\n",
    "class SplinterDataset(Dataset):\n",
    "    '''Splinter is the name of our local Ge detector'''\n",
    "\n",
    "    def __init__(self, event_dset=\"DetectorPulses.pickle\", siggen_dset=\"SimulatedPulses.pickle\", n_max=1e5, chi_squared_threshold=1, popt_threshold_under=-2, popt_threshold_over=2):\n",
    "        self.n_max = n_max\n",
    "        self.chi_squared_threshold = chi_squared_threshold\n",
    "        self.popt_threshold_over = popt_threshold_over\n",
    "        self.popt_threshold_under = popt_threshold_under\n",
    "        self.chi_squared_coeff = []\n",
    "        self.tau_fits = []\n",
    "        self.event_dict, self.siggen_dict = self.event_loader_synchronized(event_dset, siggen_dset)\n",
    "        print(\"Number of Data events:\", len(self.event_dict))\n",
    "        print(\"Number of Simulations events:\", len(self.siggen_dict))\n",
    "        self.size = min(len(self.event_dict), len(self.siggen_dict))\n",
    "        self.event_ids = [wdict[\"event\"] for wdict in self.siggen_dict]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the minimum size between event_dict and siggen_dict to avoid out-of-range errors\n",
    "        return min(len(self.event_dict), len(self.siggen_dict))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Use a single simulated waveform based on the index and transform it\n",
    "        siggenwf = self.transform(self.siggen_dict[idx][\"wf\"], self.siggen_dict[idx][\"tp0\"], sim=True)\n",
    "        # Transform the real waveform for comparison or any other purpose\n",
    "        real_wf = self.transform(self.event_dict[idx][\"wf\"], self.event_dict[idx][\"tp0\"])\n",
    "        event_id = self.siggen_dict[idx].get(\"event\", -1)  # Default to -1 or suitable value if not found\n",
    "        return real_wf[None, :], siggenwf[None, :], self.event_dict[idx], self.event_dict[idx]\n",
    "\n",
    "    def normalize_waveform(self, wf):\n",
    "        \"\"\"Normalize waveform by dividing by the average of the last norm_samples samples and shifting the waveform \n",
    "           so that the average of the first 200 samples is zero.\"\"\"\n",
    "        tail_mean = np.mean(wf[-norm_samples:])\n",
    "        if tail_mean != 0:\n",
    "            normalized_wf = wf * norm_tail_height / tail_mean\n",
    "        else:\n",
    "            normalized_wf = wf  # Avoid division by zero\n",
    "        first_200_mean = np.mean(normalized_wf[:200])\n",
    "        normalized_wf = normalized_wf - first_200_mean\n",
    "        return normalized_wf\n",
    "\n",
    "    # def normalize_sim_waveform(self, wf):\n",
    "    #     \"\"\"Normalize waveform to have values between 0 and 1.\"\"\"\n",
    "    #     min_val = np.min(wf)\n",
    "    #     max_val = np.max(wf)\n",
    "    #     if max_val > min_val:\n",
    "    #         return (wf - min_val) / (max_val - min_val)\n",
    "    #     else:\n",
    "    #         return np.zeros_like(wf)  # Handle constant waveforms\n",
    "\n",
    "    def transform(self, wf, tp0, sim=False):\n",
    "        \"\"\"Transform waveform by padding based on tp0 and then normalizing.\"\"\"\n",
    "        wf = np.array(wf)\n",
    "        tp0 = int(round(tp0))\n",
    "        left_padding = max(LSPAN - tp0, 0)\n",
    "        right_padding = max((RSPAN + tp0) - len(wf), 0)\n",
    "        wf_padded = np.pad(wf, (left_padding, right_padding), mode='edge')\n",
    "        tp0_adjusted = tp0 + left_padding\n",
    "        wf_sliced = wf_padded[(tp0_adjusted - LSPAN):(tp0_adjusted + RSPAN)]\n",
    "        wf_normalized = self.normalize_waveform(wf_sliced)\n",
    "        return wf_normalized\n",
    "\n",
    "    def event_loader_synchronized(self, data_address, sim_address):\n",
    "        data_wf_list = []\n",
    "        sim_wf_list = []\n",
    "        count = 0\n",
    "\n",
    "        print(\"Chi squared cut is\", self.chi_squared_threshold)\n",
    "        print(\"Tail slope cut over is\", self.popt_threshold_over)\n",
    "        print(\"Tail slope cut under is\", self.popt_threshold_under)\n",
    "\n",
    "        with open(data_address, \"rb\") as data_file, open(sim_address, \"rb\") as sim_file:\n",
    "            while True:\n",
    "                if count > self.n_max:\n",
    "                    break\n",
    "                try:\n",
    "                    data_wdict = pickle.load(data_file, encoding='latin1')\n",
    "                    sim_wdict = pickle.load(sim_file, encoding='latin1')\n",
    "\n",
    "                    data_wf = data_wdict[\"wf\"]\n",
    "                    sim_wf = sim_wdict[\"wf\"]\n",
    "\n",
    "                    try:\n",
    "                        data_tp0 = calculate_tn(data_wf, t_n)\n",
    "                        sim_tp0 = calculate_tn(sim_wf, t_n)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    data_wdict[\"tp0\"] = data_tp0\n",
    "                    sim_wdict[\"tp0\"] = sim_tp0\n",
    "\n",
    "                    data_transformed_wf = self.transform(data_wf, data_tp0)\n",
    "                    sim_transformed_wf = self.transform(sim_wf, sim_tp0)\n",
    "\n",
    "                    # Apply the same cuts to both data and simulation\n",
    "                    if self.check_valid_sim_waveform(data_transformed_wf) and self.check_valid_sim_waveform(sim_transformed_wf):\n",
    "                        data_wf_list.append(data_wdict)\n",
    "                        sim_wf_list.append(sim_wdict)\n",
    "                        count += 1\n",
    "\n",
    "                    if count % 10000 == 0:\n",
    "                        print(f\"{count} waveform pairs loaded.\")\n",
    "\n",
    "                except EOFError:\n",
    "                    break\n",
    "\n",
    "        return data_wf_list, sim_wf_list\n",
    "\n",
    "    def check_valid_waveform(self, wf):\n",
    "        \"\"\"Checks if a data waveform is valid based on defined criteria.\"\"\"\n",
    "        mean_first_250 = np.mean(wf[:250])\n",
    "        return (\n",
    "            len(wf) == SEQ_LEN and\n",
    "            not np.any(np.isnan(wf)) and\n",
    "            np.any(wf != 0) and\n",
    "            np.all(np.array(wf[:250]) <= 0.01) and\n",
    "            np.all(np.array(wf[-50:]) >= tail_thres) and\n",
    "            mean_first_250 <= base_thres\n",
    "        )\n",
    "\n",
    "    def check_valid_sim_waveform(self, wf):\n",
    "        \"\"\"Checks if a simulated waveform is valid based on defined criteria, including no decreases.\"\"\"\n",
    "        mean_first_250 = np.mean(wf[:250])\n",
    "        return (\n",
    "            len(wf) == SEQ_LEN and\n",
    "            not np.any(np.isnan(wf)) and\n",
    "            np.any(wf != 0) and\n",
    "            np.all(np.array(wf[:250]) <= 0.01) and\n",
    "            np.all(np.array(wf[-50:]) >= tail_thres) and\n",
    "            mean_first_250 <= base_thres and\n",
    "            np.all(np.diff(wf[:400]) >= 0)  # Ensure the waveform never decreases\n",
    "        )\n",
    "\n",
    "    def plot_waveform(self):\n",
    "        num_waveforms_to_plot = 100\n",
    "\n",
    "        # Create the first figure for all data waveforms\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for i in range(num_waveforms_to_plot):\n",
    "            real_wf, sim_wf, _, _ = self.__getitem__(i)\n",
    "            plt.plot(real_wf[0], linewidth=0.5)\n",
    "\n",
    "        plt.title(f\"{num_waveforms_to_plot} Data Pulses\")\n",
    "        plt.xlabel(\"Time Sample [ns]\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "        plt.savefig('figs/all_data_pulses.png', dpi=200)\n",
    "        plt.show()\n",
    "\n",
    "        # Create the second figure for all simulated waveforms\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for i in range(num_waveforms_to_plot):\n",
    "            real_wf, sim_wf, _, _ = self.__getitem__(i)\n",
    "            plt.plot(sim_wf[0], linewidth=0.5)\n",
    "\n",
    "        plt.title(f\"{num_waveforms_to_plot} Simulated Pulses\")\n",
    "        plt.xlabel(\"Time Sample [ns]\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "        plt.savefig('figs/all_simulated_pulses.png', dpi=200)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d7218-680c-43b6-bd17-0f779ab2cc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi squared cut is 100\n",
      "Tail slope cut over is 10\n",
      "Tail slope cut under is -10\n"
     ]
    }
   ],
   "source": [
    "dataset = SplinterDataset(det_pulses, sim_pulses, n_max=max_sample-1, chi_squared_threshold=100, popt_threshold_under=-10, popt_threshold_over=10)\n",
    "validation_split = 0.0\n",
    "shuffle_dataset = True\n",
    "random_seed= 42222\n",
    "indices = np.arange(len(dataset))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "split = int(validation_split*len(dataset))\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = data_utils.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler,  drop_last=True)\n",
    "test_loader = data_utils.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=valid_sampler,  drop_last=True)\n",
    "data = inf_train_gen(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf98c1-4a81-4092-b44d-43c6ea471b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot_waveform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e931a-b255-43b8-a9e0-6ffe695baf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script contains the PositionalUNet network along with 3 candidate discriminators:\n",
    "* RNN+Attention discriminator\n",
    "* CNN+PositionalEncoding Discriminator\n",
    "* Fully Connected Discriminators\n",
    "we have tested all 3 discriminators, and the RNN+Attention works the best.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataset import SEQ_LEN\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    '''\n",
    "    Double convolutional layer followed by Batch Normalization and LeakyReLU activation function.\n",
    "    This is used in the U-Net model to perform downsampling and feature extraction.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, mid_channels, kernel_size=11, padding=5, bias=False),\n",
    "            nn.BatchNorm1d(mid_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv1d(mid_channels, out_channels, kernel_size=7, padding=3, bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    '''\n",
    "    Downsampling step for U-Net. Uses max pooling followed by double convolution.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    '''\n",
    "    Upsampling step for U-Net. Uses transposed convolution (or bilinear upsampling) and double convolution.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='linear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose1d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        x1 = F.pad(x1, [diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    '''\n",
    "    Final output convolution layer used to reduce the channels to the desired number of output channels.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Positional encoding for capturing relative positions in the sequence.\n",
    "    This is useful for incorporating positional information into the U-Net model.\n",
    "    '''\n",
    "    def __init__(self, d_model, start=0, dropout=0.1, max_len=10000, factor=1.0):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.factor = factor\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(1, 2)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.start = start\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.factor * self.pe[:, :, self.start:(self.start + x.size(2))]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class PositionalUNet(nn.Module):\n",
    "    '''\n",
    "    U-Net with positional encoding for both encoding and decoding steps.\n",
    "    This network is designed to process pulse signals and extract high-level features.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(PositionalUNet, self).__init__()\n",
    "        self.bilinear = True\n",
    "        multi = 40\n",
    "\n",
    "        self.inc = DoubleConv(1, multi)\n",
    "        self.down1 = Down(multi, multi * 2)\n",
    "        self.down2 = Down(multi * 2, multi * 4)\n",
    "        self.down3 = Down(multi * 4, multi * 8)\n",
    "        factor = 2 if self.bilinear else 1\n",
    "        self.down4 = Down(multi * 8, multi * 16 // factor)\n",
    "\n",
    "        self.fc_mean = torch.nn.Conv1d(multi * 16 // factor, multi * 16 // factor, 1)\n",
    "        self.fc_var = torch.nn.Conv1d(multi * 16 // factor, multi * 16 // factor, 1)\n",
    "\n",
    "        self.up1 = Up(multi * 16, multi * 8 // factor, self.bilinear)\n",
    "        self.up2 = Up(multi * 8, multi * 4 // factor, self.bilinear)\n",
    "        self.up3 = Up(multi * 4, multi * 2 // factor, self.bilinear)\n",
    "        self.up4 = Up(multi * 2, multi // factor, self.bilinear)\n",
    "        self.outc = OutConv(multi // factor, 1)\n",
    "\n",
    "        self.pe1 = PositionalEncoding(multi)\n",
    "        self.pe2 = PositionalEncoding(multi * 2)\n",
    "        self.pe3 = PositionalEncoding(multi * 4)\n",
    "        self.pe4 = PositionalEncoding(multi * 8)\n",
    "        self.pe5 = PositionalEncoding(multi * 16 // factor)\n",
    "        self.pe6 = PositionalEncoding(multi * 8 // factor, start=multi * 4)\n",
    "        self.pe7 = PositionalEncoding(multi * 4 // factor, start=multi * 2)\n",
    "        self.pe8 = PositionalEncoding(multi * 2 // factor, start=multi * 2)\n",
    "        self.pe9 = PositionalEncoding(multi // factor, start=0, factor=1.0)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        '''\n",
    "        Reparametrization trick used in variational autoencoders.\n",
    "        '''\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.randn_like(mu)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward pass for the positional U-Net model with the reparametrization step.\n",
    "        '''\n",
    "        x1 = self.pe1(self.inc(x))\n",
    "        x2 = self.pe2(self.down1(x1))\n",
    "        x3 = self.pe3(self.down2(x2))\n",
    "        x4 = self.pe4(self.down3(x3))\n",
    "        x5 = self.down4(x4)\n",
    "        x5 = self.pe5(self.reparametrize(self.fc_mean(x5), self.fc_var(x5)))\n",
    "\n",
    "        x = self.pe6(self.up1(x5, x4))\n",
    "        x = self.pe7(self.up2(x, x3))\n",
    "        x = self.pe8(self.up3(x, x2))\n",
    "        x = self.up4(x, x1)\n",
    "        output = self.outc(x)\n",
    "        return output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    '''\n",
    "    RNN with optional bidirectionality and attention mechanism.\n",
    "    This network is used as a discriminator for pulse signals.\n",
    "    '''\n",
    "    def __init__(self, get_attention=False):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        bidirec = True  # Whether to use a bidirectional RNN\n",
    "        self.bidirec = bidirec\n",
    "        feed_in_dim = 128\n",
    "        self.seg = 1  # Segment waveform to reduce its length. Set to 1 for no segmentation.\n",
    "        self.emb_dim = 64\n",
    "        self.emb_tick = 1 / 1000.0  # Embedding resolution\n",
    "        self.embedding = nn.Embedding(1000, self.emb_dim)  # Use range [0, 1000) for embedding\n",
    "        self.seq_len = (SEQ_LEN - 100) // self.seg  # Use original sequence length minus 100 samples\n",
    "\n",
    "        # Initialize RNN layers\n",
    "        if bidirec:\n",
    "            self.RNNLayer = torch.nn.GRU(input_size=self.emb_dim, hidden_size=feed_in_dim // 2, num_layers=2, batch_first=True, bidirectional=True, dropout=0.2)\n",
    "            feed_in_dim *= 2\n",
    "        else:\n",
    "            self.RNNLayer = torch.nn.GRU(input_size=self.emb_dim, hidden_size=feed_in_dim // 2, num_layers=2, batch_first=True, bidirectional=False, dropout=0.2)\n",
    "\n",
    "        self.attention_weight = nn.Linear(feed_in_dim // 2, feed_in_dim // 2, bias=False)\n",
    "        self.norm = torch.nn.BatchNorm1d(feed_in_dim // 2)\n",
    "        self.get_attention = get_attention\n",
    "\n",
    "        fc1 = feed_in_dim\n",
    "        self.fcnet = nn.Linear(fc1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward pass for the RNN with optional attention mechanism.\n",
    "        '''\n",
    "        # Skip the first 50 and last 50 points, leaving a sequence length of 700\n",
    "        x = x[:, :, 50:-50]\n",
    "\n",
    "        # Reshape input according to segmentation (batch_size, seq_len)\n",
    "        x = x.view(-1, self.seq_len)\n",
    "\n",
    "        # Clip values to be within embedding range [0, 1000)\n",
    "        x = torch.clamp(x / self.emb_tick, 0, 999).long()\n",
    "\n",
    "        # Embedding lookup\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        bsize = x.size(0)  # Batch size\n",
    "        output, hidden = self.RNNLayer(x)\n",
    "\n",
    "        # Process hidden state for bidirectional/unidirectional RNN\n",
    "        if self.bidirec:\n",
    "            hidden = hidden[-2:]  # Get last hidden state for bidirectional RNN\n",
    "            hidden = hidden.transpose(0, 1).reshape(bsize, -1)\n",
    "        else:\n",
    "            hidden = hidden[-1]  # Get last hidden state for unidirectional RNN\n",
    "\n",
    "        # Calculate attention scores\n",
    "        attention_scores = self.calculate_attention_scores(output, hidden)\n",
    "\n",
    "        if self.get_attention:\n",
    "            return attention_scores  # Return attention scores if get_attention flag is True\n",
    "\n",
    "        # Apply attention scores\n",
    "        context = torch.sum(attention_scores.unsqueeze(-1).expand_as(output) * output, dim=1)\n",
    "\n",
    "        # Pass through fully connected layer\n",
    "        x = self.fcnet(torch.cat([context, hidden], dim=-1))\n",
    "\n",
    "        return torch.sigmoid(x)  # Return sigmoid output (between 0 and 1)\n",
    "\n",
    "    def calculate_attention_scores(self, output, hidden):\n",
    "        '''\n",
    "        Compute attention scores based on the output and hidden states.\n",
    "        '''\n",
    "        inner_product = torch.einsum(\"ijl,il->ij\", output, hidden)\n",
    "        attention_scores = torch.softmax(inner_product, dim=-1)\n",
    "        return attention_scores\n",
    "\n",
    "    def get_attention_weights(self, x):\n",
    "        '''\n",
    "        Return attention weights explicitly if needed.\n",
    "        '''\n",
    "        self.get_attention_flag = True  # Ensure the model returns attention scores\n",
    "        attention_weights = self.forward(x)\n",
    "        self.get_attention_flag = False  # Reset the flag\n",
    "        return attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350da0e-be5d-401b-84ef-a32b79823d78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WFDist(nn.Module):\n",
    "    '''\n",
    "    Waveform Distance, this is a special type of L1 loss which gives more weight to the\n",
    "    rising and falling edge of each pulse\n",
    "    baseline(0,250) rising edge=(250,500), tail=(500,800)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, baseline_weight, ris_edge_weight, tail_weight):\n",
    "        super(WFDist, self).__init__()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weight = torch.tensor([baseline_weight]*baseline_len+[ris_edge_weight]*rising_edge_len+[tail_weight]*tail_len).to(DEVICE)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        loss_out = 0.0\n",
    "        for i in range(x1.size(0)):\n",
    "            loss_out += self.criterion(x1[i].view(-1)*self.weight, x2[i].view(-1)*self.weight)#/self.weight.sum()\n",
    "        return loss_out/x1.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16267dc0-a6f2-4f68-89f1-d371a6c14991",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_real = torch.ones(BATCH_SIZE,1).to(DEVICE) #tensor to hold \n",
    "target_fake = torch.zeros(BATCH_SIZE,1).to(DEVICE)\n",
    "netG_A2B = PositionalUNet() # Generator from Data to Simulations (ATN)\n",
    "netG_B2A = PositionalUNet() # Generator from Simulations to Data (IATN)\n",
    "netD_A = RNN().apply(weights_init_normal) # Discriminator whose job is to verigy is a pulse looks like data\n",
    "netD_B = RNN().apply(weights_init_normal) # Discriminator whose job is to verigy is a pulse looks like simulations\n",
    "netG_A2B.to(DEVICE)\n",
    "netG_B2A.to(DEVICE)\n",
    "netD_A.to(DEVICE)\n",
    "netD_B.to(DEVICE)\n",
    "criterion_GAN = nn.BCELoss().to(DEVICE)\n",
    "criterion_cycle = WFDist(baseline_weight, ris_edge_weight, tail_weight).to(DEVICE)\n",
    "criterion_identity = WFDist(baseline_weight, ris_edge_weight, tail_weight).to(DEVICE)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=LRATE_Gen, betas=(0.5, 0.999), weight_decay=w_decay)\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=LRATE_Disc, betas=(0.5, 0.999), weight_decay=w_decay)\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=LRATE_Disc, betas=(0.5, 0.999), weight_decay=w_decay)\n",
    "\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(ITERS, 0, DECAY).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(ITERS, 0, DECAY).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(ITERS, 0, DECAY).step)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total trainable parameters in netG_A2B: {count_parameters(netG_A2B)}\")\n",
    "print(f\"Total trainable parameters in netG_B2A: {count_parameters(netG_B2A)}\")\n",
    "print(f\"Total trainable parameters in netD_A: {count_parameters(netD_A)}\")\n",
    "print(f\"Total trainable parameters in netD_B: {count_parameters(netD_B)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc125d-fec1-4da0-a5bd-4b68ff24e761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "label_smoothing = 1\n",
    "# Directory to save the model weights\n",
    "save_dir = \"/work/users/k/b/kbhimani/cpu_net_weights/validation\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "# Function to check for NaN values and stop training if found\n",
    "def check_for_nan(tensor, name):\n",
    "    if torch.isnan(tensor).any():\n",
    "        print(f\"NaN detected in {name}. Stopping training.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "losses_G = []\n",
    "losses_D_A = []\n",
    "losses_D_B = []\n",
    "losses_GAN_A2B = []\n",
    "losses_GAN_B2A = []\n",
    "losses_identity_A = []\n",
    "losses_identity_B = []\n",
    "losses_cycle_ABA = []\n",
    "losses_cycle_BAB = []\n",
    "learning_rates_G = []\n",
    "l1_data_sim = []\n",
    "\n",
    "for iteration in tqdm(range(ITERS)):\n",
    "    netG_A2B.train()\n",
    "    netG_B2A.train()\n",
    "\n",
    "    #########################\n",
    "    # A: Detector Pulses\n",
    "    # B: Simulated Pulses\n",
    "    #########################\n",
    "\n",
    "    real_A, real_B = next(data)\n",
    "    real_A = real_A.to(DEVICE).float()\n",
    "    real_B = real_B.to(DEVICE).float()\n",
    "\n",
    "    # Check for NaN values in real pulses\n",
    "    if check_for_nan(real_A, \"real_A\") or check_for_nan(real_B, \"real_B\"):\n",
    "        break\n",
    "\n",
    "    ###### Generators A2B and B2A ######\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # Identity loss\n",
    "    same_B = netG_A2B(real_B)\n",
    "    if check_for_nan(same_B, \"same_B\"):\n",
    "        break\n",
    "    loss_identity_B = criterion_identity(same_B, real_B) * iden_loss_weight\n",
    "\n",
    "    same_A = netG_B2A(real_A)\n",
    "    if check_for_nan(same_A, \"same_A\"):\n",
    "        break\n",
    "    loss_identity_A = criterion_identity(same_A, real_A) * iden_loss_weight\n",
    "\n",
    "    # GAN loss\n",
    "    fake_B = netG_A2B(real_A)\n",
    "    if check_for_nan(fake_B, \"fake_B\"):\n",
    "        break\n",
    "    pred_fake = netD_B(fake_B)\n",
    "    loss_GAN_A2B = criterion_GAN(pred_fake, target_real * label_smoothing) * gan_loss_weight\n",
    "\n",
    "    fake_A = netG_B2A(real_B)\n",
    "    if check_for_nan(fake_A, \"fake_A\"):\n",
    "        break\n",
    "    pred_fake = netD_A(fake_A)\n",
    "    loss_GAN_B2A = criterion_GAN(pred_fake, target_real * label_smoothing) * gan_loss_weight\n",
    "\n",
    "    # Cycle loss\n",
    "    recovered_A = netG_B2A(fake_B)\n",
    "    if check_for_nan(recovered_A, \"recovered_A\"):\n",
    "        break\n",
    "    loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * cyc_loss_weight\n",
    "\n",
    "    recovered_B = netG_A2B(fake_A)\n",
    "    if check_for_nan(recovered_B, \"recovered_B\"):\n",
    "        break\n",
    "    loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * cyc_loss_weight\n",
    "\n",
    "    l1_sim = F.l1_loss(real_A, fake_A)\n",
    "    if check_for_nan(l1_sim, \"l1_sim\"):\n",
    "        break\n",
    "\n",
    "    # Total loss for generators\n",
    "    loss_G = (\n",
    "        loss_identity_A\n",
    "        + loss_identity_B\n",
    "        + loss_cycle_ABA\n",
    "        + loss_cycle_BAB\n",
    "        + loss_GAN_A2B\n",
    "        + loss_GAN_B2A\n",
    "    )\n",
    "    if check_for_nan(loss_G, \"loss_G\"):\n",
    "        break\n",
    "    loss_G.backward()\n",
    "\n",
    "    # Apply gradient clipping for the generators\n",
    "    torch.nn.utils.clip_grad_norm_(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), max_grad_norm)\n",
    "\n",
    "    optimizer_G.step()\n",
    "\n",
    "    # Update discriminators every n_disc_iters iterations\n",
    "    if iteration % n_disc_iters  == 0 : #or iteration>5000\n",
    "        ###### Discriminator A (Detector Pulses) ######\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_A(real_A)\n",
    "        if check_for_nan(pred_real, \"pred_real (Discriminator A)\"):\n",
    "            break\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real * label_smoothing)\n",
    "\n",
    "        # Fake loss\n",
    "        pred_fake = netD_A(fake_A.detach())\n",
    "        if check_for_nan(pred_fake, \"pred_fake (Discriminator A)\"):\n",
    "            break\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss for Discriminator A\n",
    "        loss_D_A = loss_D_real + loss_D_fake\n",
    "        if check_for_nan(loss_D_A, \"loss_D_A\"):\n",
    "            break\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        # Apply gradient clipping for Discriminator A\n",
    "        torch.nn.utils.clip_grad_norm_(netD_A.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        ###### Discriminator B (Simulated Pulses) ######\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_B(real_B)\n",
    "        if check_for_nan(pred_real, \"pred_real (Discriminator B)\"):\n",
    "            break\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real * label_smoothing)\n",
    "\n",
    "        # Fake loss\n",
    "        pred_fake = netD_B(fake_B.detach())\n",
    "        if check_for_nan(pred_fake, \"pred_fake (Discriminator B)\"):\n",
    "            break\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss for Discriminator B\n",
    "        loss_D_B = loss_D_real + loss_D_fake\n",
    "        if check_for_nan(loss_D_B, \"loss_D_B\"):\n",
    "            break\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        # Apply gradient clipping for Discriminator B\n",
    "        torch.nn.utils.clip_grad_norm_(netD_B.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "    current_lr_G = lr_scheduler_G.get_last_lr()[0]\n",
    "    # Append each loss to its corresponding list\n",
    "    losses_G.append(loss_G.item())\n",
    "    losses_D_A.append(loss_D_A.item())\n",
    "    losses_D_B.append(loss_D_B.item())\n",
    "    losses_GAN_A2B.append(loss_GAN_A2B.item())\n",
    "    losses_GAN_B2A.append(loss_GAN_B2A.item())\n",
    "    losses_identity_A.append(loss_identity_A.item())\n",
    "    losses_identity_B.append(loss_identity_B.item())\n",
    "    losses_cycle_ABA.append(loss_cycle_ABA.item())\n",
    "    losses_cycle_BAB.append(loss_cycle_BAB.item())\n",
    "    learning_rates_G.append(current_lr_G)\n",
    "    l1_data_sim.append(l1_sim.item())\n",
    "\n",
    "    lr_scheduler_G.step()\n",
    "    # lr_scheduler_D_A.step()\n",
    "    # lr_scheduler_D_B.step()\n",
    "\n",
    "    # Save model weights every 50 iterations\n",
    "    if iteration % 50 == 0:\n",
    "        torch.save(netG_B2A.state_dict(), f\"{save_dir}/netG_B2A_iter_{iteration}.pt\")\n",
    "        torch.save(netG_A2B.state_dict(), f\"{save_dir}/netG_A2B_iter_{iteration}.pt\")\n",
    "        torch.save(netD_A.state_dict(), f\"{save_dir}/netD_A_iter_{iteration}.pth\")\n",
    "        torch.save(netD_B.state_dict(), f\"{save_dir}/netD_B_iter_{iteration}.pth\")\n",
    "\n",
    "    # if iteration % 50 == 0:\n",
    "    #     print(f\"Iteration {iteration}: Loss_G: {loss_G.item()}, Loss_D_A: {loss_D_A.item()}, Loss_D_B: {loss_D_B.item()}\")\n",
    "\n",
    "# Save final model weights and loss arrays to disk\n",
    "torch.save(netG_B2A.state_dict(), f\"data_emulation/model_weights/{eng_peak}_ATN.pt\")\n",
    "torch.save(netG_A2B.state_dict(), f\"data_emulation/model_weights/{eng_peak}_IATN.pt\")\n",
    "torch.save(netD_A.state_dict(), f\"data_emulation/model_weights/{eng_peak}_netD_A.pth\")\n",
    "torch.save(netD_B.state_dict(), f\"data_emulation/model_weights/{eng_peak}_netD_B.pth\")\n",
    "\n",
    "\n",
    "# Save loss arrays\n",
    "np.save(\"data_emulation/plot_data/losses_G.npy\", np.array(losses_G))\n",
    "np.save(\"data_emulation/plot_data/losses_D_A.npy\", np.array(losses_D_A))\n",
    "np.save(\"data_emulation/plot_data/losses_D_B.npy\", np.array(losses_D_B))\n",
    "np.save(\"data_emulation/plot_data/losses_GAN_A2B.npy\", np.array(losses_GAN_A2B))\n",
    "np.save(\"data_emulation/plot_data/losses_GAN_B2A.npy\", np.array(losses_GAN_B2A))\n",
    "np.save(\"data_emulation/plot_data/losses_identity_A.npy\", np.array(losses_identity_A))\n",
    "np.save(\"data_emulation/plot_data/losses_identity_B.npy\", np.array(losses_identity_B))\n",
    "np.save(\"data_emulation/plot_data/losses_cycle_ABA.npy\", np.array(losses_cycle_ABA))\n",
    "np.save(\"data_emulation/plot_data/losses_cycle_BAB.npy\", np.array(losses_cycle_BAB))\n",
    "np.save(\"data_emulation/plot_data/learning_rates_G.npy\", np.array(learning_rates_G))\n",
    "np.save(\"data_emulation/plot_data/l1_data_sim.npy\", np.array(l1_data_sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68692c6-dfbc-41df-8403-ac787a5c7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_data_sim = np.load(\"data_emulation/plot_data/l1_data_sim.npy\")\n",
    "plt.plot(l1_data_sim, label='L1 Loss')\n",
    "plt.title('L1 Losses')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.minorticks_on()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0710f6-5385-4634-b716-57bbf98500b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "# Load existing losses\n",
    "losses_G = np.load(\"data_emulation/plot_data/losses_G.npy\")\n",
    "losses_D_A = np.load(\"data_emulation/plot_data/losses_D_A.npy\")\n",
    "losses_D_B = np.load(\"data_emulation/plot_data/losses_D_B.npy\")\n",
    "losses_GAN_A2B = np.load(\"data_emulation/plot_data/losses_GAN_A2B.npy\")\n",
    "losses_GAN_B2A = np.load(\"data_emulation/plot_data/losses_GAN_B2A.npy\")\n",
    "losses_identity_A = np.load(\"data_emulation/plot_data/losses_identity_A.npy\")\n",
    "losses_identity_B = np.load(\"data_emulation/plot_data/losses_identity_B.npy\")\n",
    "losses_cycle_ABA = np.load(\"data_emulation/plot_data/losses_cycle_ABA.npy\")\n",
    "losses_cycle_BAB = np.load(\"data_emulation/plot_data/losses_cycle_BAB.npy\")\n",
    "\n",
    "\n",
    "# Set the moving average window\n",
    "win = 10\n",
    "# Create a figure with a grid of 2x3 subplots to include the new loss plots\n",
    "plt.figure(figsize=(25, 12))\n",
    "iterations = np.linspace(1,len(losses_G)-win+1,len(losses_G)-win+1)\n",
    "\n",
    "cut = (iterations>0)\n",
    "\n",
    "# Discriminator Losses\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(iterations[cut], moving_average(losses_D_A, win)[cut], label='Data')\n",
    "plt.plot(iterations[cut], moving_average(losses_D_B, win)[cut], label='Simulation')\n",
    "plt.title('Discriminator Losses')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.minorticks_on()\n",
    "plt.legend()\n",
    "\n",
    "# Generator Losses\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(iterations[cut], moving_average(losses_GAN_A2B, win)[cut], label='Data to Simulation')\n",
    "plt.plot(iterations[cut], moving_average(losses_GAN_B2A, win)[cut], label='Simulation to Data')\n",
    "plt.title('Generator Losses')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.minorticks_on()\n",
    "plt.legend()\n",
    "\n",
    "# Identity Losses\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(iterations, moving_average(losses_identity_A, win), label='Data')\n",
    "plt.plot(iterations, moving_average(losses_identity_B, win), label='Simulation')\n",
    "plt.title('Identity Losses')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.minorticks_on()\n",
    "plt.legend()\n",
    "\n",
    "# Cycle Consistency Losses\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(iterations, moving_average(losses_cycle_ABA, win), label='Data to Simulation to Data')\n",
    "plt.plot(iterations, moving_average(losses_cycle_BAB, win), label='Simulation to Data to Simulation')\n",
    "plt.title('Cycle Consistency Losses')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.minorticks_on()\n",
    "plt.legend()\n",
    "\n",
    "# # Tail Slope Distribution Losses A\n",
    "# plt.subplot(2, 3, 5)\n",
    "# plt.plot(moving_average(tail_slope_losses_A, win), label='Tail Slope Loss A')\n",
    "# plt.title('Tail Slope Distribution Losses A')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.yscale('log')\n",
    "# plt.minorticks_on()\n",
    "# plt.legend()\n",
    "\n",
    "# # Tail Slope Distribution Losses B\n",
    "# plt.subplot(2, 3, 6)\n",
    "# plt.plot(moving_average(tail_slope_losses_B, win), label='Tail Slope Loss B')\n",
    "# plt.title('Tail Slope Distribution Losses B')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.yscale('log')\n",
    "# plt.minorticks_on()\n",
    "# plt.legend()\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figs/loss_funcs_with_tail_slope.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f99caa-fa04-41b1-9616-e290aab87138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ATN = PositionalUNet()\n",
    "ATN.to(DEVICE)\n",
    "pretrained_dict = torch.load(f'data_emulation/model_weights/{eng_peak}_ATN.pt', weights_only=True)\n",
    "# pretrained_dict = torch.load('fep_training/ATN_epoch_1.pt')\n",
    "model_dict = ATN.state_dict()\n",
    "model_dict.update(pretrained_dict) \n",
    "ATN.load_state_dict(pretrained_dict)\n",
    "ATN.eval()\n",
    "\n",
    "IATN = PositionalUNet()\n",
    "IATN.to(DEVICE)\n",
    "pretrained_dict_inv = torch.load(f'data_emulation/model_weights/{eng_peak}_IATN.pt', weights_only=True)\n",
    "# pretrained_dict = torch.load('fep_training/ATN_epoch_1.pt')\n",
    "\n",
    "model_dict_inv = IATN.state_dict()\n",
    "model_dict_inv.update(pretrained_dict_inv) \n",
    "IATN.load_state_dict(pretrained_dict_inv)\n",
    "IATN.eval()\n",
    "data_dict_loader = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e969a35-815e-43f7-b2bc-2d4d92996f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wf, wf_deconv, a,b = next(iter(train_loader))\n",
    "wf = wf.to(DEVICE)\n",
    "wf_deconv = wf_deconv.to(DEVICE)\n",
    "outputs  = ATN(wf_deconv)\n",
    "outputs_inv = IATN(outputs)\n",
    "iwf = 2 # the ith waveform in the batch to plot\n",
    "detector_pulse = wf[iwf,0,:].cpu().data.numpy().flatten()\n",
    "simulated_pulse = wf_deconv[iwf,0,:].cpu().data.numpy().flatten()\n",
    "translated_pulse = outputs[iwf,0,:].cpu().data.numpy().flatten()\n",
    "translated_pulse_inv = outputs_inv[iwf,0,:].cpu().data.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520b342-b9b4-47fc-b1a1-c79948dfb9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plot_steps_gif=5000\n",
    "# Directories to save attention weights plots\n",
    "attention_weights_dir = \"/nas/longleaf/home/kbhimani/CPU-Net/data_emulation/giffs/attention_weights\"\n",
    "os.makedirs(attention_weights_dir, exist_ok=True)\n",
    "\n",
    "def visualize_attention_weights_stacked(model_A, model_B, train_loader, device, num_steps, save_dir):\n",
    "    # Get a single batch from the train loader\n",
    "    real_A, real_B, _, _ = next(iter(train_loader))\n",
    "    \n",
    "    # Assume real_A and real_B are already on the correct device and normalized if necessary\n",
    "    real_A = real_A.to(device)\n",
    "    real_B = real_B.to(device)\n",
    "\n",
    "    for step in tqdm(range(0, num_steps, 50)):\n",
    "        # Load saved weights for both models\n",
    "        model_A.load_state_dict(torch.load(f\"/work/users/k/b/kbhimani/cpu_net_weights/validation/netD_A_iter_{step}.pth\",weights_only=True, map_location=device))\n",
    "        model_B.load_state_dict(torch.load(f\"/work/users/k/b/kbhimani/cpu_net_weights/validation/netD_B_iter_{step}.pth\",weights_only=True, map_location=device))\n",
    "        \n",
    "        model_A.eval()\n",
    "        model_B.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            attention_weights_A = model_A.get_attention_weights(real_A).cpu().numpy()[0]\n",
    "            attention_weights_B = model_B.get_attention_weights(real_B).cpu().numpy()[0]\n",
    "        \n",
    "        # Add padding to match pulse length\n",
    "        # attention_weights_A_padded = attention_weights_A\n",
    "        # attention_weights_B_padded = attention_weights_B\n",
    "        attention_weights_A_padded = np.pad(attention_weights_A, (50, 50), mode='constant')\n",
    "        attention_weights_B_padded = np.pad(attention_weights_B, (50, 50), mode='constant')\n",
    "\n",
    "        # Plot the attention weights (stacked vertically)\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(10, 10))  # Two rows for the attention weights\n",
    "\n",
    "        time = np.arange(800)\n",
    "\n",
    "        axs[0].plot(time, attention_weights_A_padded, label=\"Attention Weights A\", color='tab:blue')\n",
    "        axs[0].set_title(f'Attention Weights for Model A (Step {step})')\n",
    "        axs[0].set_xlabel('Time Steps')\n",
    "        axs[0].set_ylabel('Attention Score')\n",
    "        axs[0].grid(True)\n",
    "\n",
    "        axs[1].plot(time, attention_weights_B_padded, label=\"Attention Weights B\", color='tab:red')\n",
    "        axs[1].set_title(f'Attention Weights for Model B (Step {step})')\n",
    "        axs[1].set_xlabel('Time Steps')\n",
    "        axs[1].set_ylabel('Attention Score')\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{save_dir}/attention_weights_step_{step}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Call the function\n",
    "netD_A = RNN(get_attention=True)\n",
    "netD_B = RNN(get_attention=True)\n",
    "visualize_attention_weights_stacked(netD_A, netD_B, train_loader, 'cpu', num_steps=plot_steps_gif, save_dir=attention_weights_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7557a9-a497-4b7a-8221-5ec1e7dbae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle ABA and BAB directories\n",
    "cycle_aba_dir = \"/nas/longleaf/home/kbhimani/CPU-Net/data_emulation/giffs/cycle_aba\"\n",
    "os.makedirs(cycle_aba_dir, exist_ok=True)\n",
    "\n",
    "cycle_bab_dir = \"/nas/longleaf/home/kbhimani/CPU-Net/data_emulation/giffs/cycle_bab\"\n",
    "os.makedirs(cycle_bab_dir, exist_ok=True)\n",
    "\n",
    "def plot_cycle_ABA_through_training(netG_A2B, netG_B2A, train_loader, device, num_steps, save_dir):\n",
    "    # Get a single batch from the train loader\n",
    "    real_A, real_B, _, _ = next(iter(train_loader))\n",
    "    real_A = real_A.to(device)\n",
    "    real_B = real_B.to(device)\n",
    "\n",
    "    time = np.linspace(0, 799, 800)\n",
    "\n",
    "    for step in tqdm(range(0, num_steps, 50)):\n",
    "        # Load saved weights for both models\n",
    "        netG_A2B.load_state_dict(torch.load(f\"/work/users/k/b/kbhimani/cpu_net_weights/validation/netG_A2B_iter_{step}.pt\"))\n",
    "        netG_B2A.load_state_dict(torch.load(f\"/work/users/k/b/kbhimani/cpu_net_weights/validation/netG_B2A_iter_{step}.pt\"))\n",
    "        \n",
    "        netG_A2B.eval()\n",
    "        netG_B2A.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_B = netG_A2B(real_A)\n",
    "            recovered_A = netG_B2A(fake_B)\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(time, real_A[0, 0, :].cpu().numpy(), label=\"Target Detector Pulse (Real A)\", color=\"#0072BD\", linestyle=\":\")\n",
    "        plt.plot(time, fake_B[0, 0, :].cpu().numpy(), label=\"Translated Pulse (Fake B)\", color=\"#D95319\")\n",
    "        plt.plot(time, recovered_A[0, 0, :].cpu().numpy(), label=\"Recovered Pulse (Recovered A)\", color=\"#7E2F8E\")\n",
    "        \n",
    "        plt.title(f\"Cycle ABA at Step {step}\")\n",
    "        plt.xlabel(\"Time [ns]\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{save_dir}/cycle_aba_step_{step}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Call the function\n",
    "plot_cycle_ABA_through_training(IATN, ATN, train_loader, DEVICE, num_steps=plot_steps_gif, save_dir=cycle_aba_dir)\n",
    "\n",
    "def plot_cycle_BAB_through_training(netG_A2B, netG_B2A, train_loader, device, num_steps, save_dir):\n",
    "    # Get a single batch from the train loader\n",
    "    real_A, real_B, _, _ = next(iter(train_loader))\n",
    "    real_A = real_A.to(device)\n",
    "    real_B = real_B.to(device)\n",
    "\n",
    "    time = np.linspace(0, 799, 800)\n",
    "    \n",
    "    for step in tqdm(range(0, num_steps, 50)):\n",
    "        # Load saved weights for both models\n",
    "        netG_A2B.load_state_dict(torch.load(f\"/work/users/k/b/kbhimani/cpu_net_weights/validation/netG_A2B_iter_{step}.pt\"))\n",
    "        netG_B2A.load_state_dict(torch.load(f\"/work/users/k/b/kbhimani/cpu_net_weights/validation/netG_B2A_iter_{step}.pt\"))\n",
    "        \n",
    "        netG_A2B.eval()\n",
    "        netG_B2A.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_A = netG_B2A(real_B)\n",
    "            recovered_B = netG_A2B(fake_A)\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(time, real_B[0, 0, :].cpu().numpy(), label=\"Target Simulated Pulse (Real B)\", color=\"#0072BD\", linestyle=\":\")\n",
    "        plt.plot(time, fake_A[0, 0, :].cpu().numpy(), label=\"Translated Pulse (Fake A)\", color=\"#D95319\")\n",
    "        plt.plot(time, recovered_B[0, 0, :].cpu().numpy(), label=\"Recovered Pulse (Recovered B)\", color=\"#7E2F8E\")\n",
    "        \n",
    "        plt.title(f\"Cycle BAB at Step {step}\")\n",
    "        plt.xlabel(\"Time [ns]\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{save_dir}/cycle_bab_step_{step}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Call the function\n",
    "plot_cycle_BAB_through_training(IATN, ATN, train_loader, DEVICE, num_steps=plot_steps_gif, save_dir=cycle_bab_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d84a3-71bc-4937-a798-d15783160c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_attention_weights_for_both(model_A, model_B, weights_path_A, weights_path_B, test_loader, device):\n",
    "    # Load the saved weights for both models\n",
    "    model_A.load_state_dict(torch.load(weights_path_A, map_location=device, weights_only=True))\n",
    "    model_B.load_state_dict(torch.load(weights_path_B, map_location=device, weights_only=True))\n",
    "    \n",
    "    # Set both models to evaluation mode\n",
    "    model_A.eval()\n",
    "    model_B.eval()\n",
    "    \n",
    "    # Get a single batch from the test loader\n",
    "    real_A, real_B, a, b = next(iter(test_loader))\n",
    "    \n",
    "    # Assume real_A and real_B are already on the correct device and normalized if necessary\n",
    "    real_A = real_A.to(device)\n",
    "    real_B = real_B.to(device)\n",
    "\n",
    "    # Get the attention weights for the single input instance from both models\n",
    "    with torch.no_grad():\n",
    "        attention_weights_A = model_A.get_attention_weights(real_A).cpu().numpy()[0]  # Assuming a method that returns attention weights\n",
    "        attention_weights_B = model_B.get_attention_weights(real_B).cpu().numpy()[0]  # Assuming a method that returns attention weights\n",
    "\n",
    "    # Add padding of 50 zeros at the start and end for both attention weights\n",
    "    attention_weights_A_padded = np.pad(attention_weights_A, (50, 50), mode='constant', constant_values=0)\n",
    "    attention_weights_B_padded = np.pad(attention_weights_B, (50, 50), mode='constant', constant_values=0)\n",
    "    \n",
    "    # Set up time intervals for the plot\n",
    "    time_intervals = [(0, 201, 'tab:blue'), (200, 451, 'tab:red'), (451, 800, 'tab:green')]\n",
    "    detector_pulses = real_A[0].cpu().numpy()[0]\n",
    "    simulated_pulses = real_B[0].cpu().numpy()[0]\n",
    "    \n",
    "    # Create figure for visualization\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 10))  # Two rows for waveforms and attention, two columns for each model\n",
    "    \n",
    "    # Plot waveform and attention weights for model A (Detector Pulses)\n",
    "    for start, end, color in time_intervals:\n",
    "        axs[0, 0].plot(np.arange(start, min(end, len(detector_pulses))), detector_pulses[start:end], color=color, label=f'{start}-{end} ns')\n",
    "    axs[0, 0].set_title('Detector Pulses')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Plot padded attention weights for detector pulses\n",
    "    axs[1, 0].plot(attention_weights_A_padded, label='Attention Weights A')\n",
    "    axs[1, 0].set_title('Attention Weights (Detector Pulses)')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Plot waveform and attention weights for model B (Simulated Pulses)\n",
    "    for start, end, color in time_intervals:\n",
    "        axs[0, 1].plot(np.arange(start, min(end, len(simulated_pulses))), simulated_pulses[start:end], color=color, label=f'{start}-{end} ns') \n",
    "    axs[0, 1].set_title('Simulated Pulses')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # Plot padded attention weights for simulated pulses\n",
    "    axs[1, 1].plot(attention_weights_B_padded, label='Attention Weights B')\n",
    "    axs[1, 1].set_title('Attention Weights (Simulated Pulses)')\n",
    "    axs[1, 1].legend()\n",
    "    \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "netD_A = RNN(get_attention=True)\n",
    "netD_B = RNN(get_attention=True)\n",
    "weights_path_A = f'data_emulation/model_weights/{eng_peak}_netD_A.pth'\n",
    "weights_path_B = f'data_emulation/model_weights/{eng_peak}_netD_B.pth'\n",
    "\n",
    "# Now call the function to visualize the attention weights for both models\n",
    "visualize_attention_weights_for_both(netD_A, netD_B, weights_path_A, weights_path_B, train_loader, 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f617ce2-fb52-4ef7-93db-ebee3c185a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cycle_BAB(netG_A2B, netG_B2A, real_A, real_B, DEVICE):\n",
    "    # Initialize to store one cycle of the waveform transformation for BAB cycle\n",
    "    time = np.linspace(0, 799, 800)  # Time axis for the waveforms\n",
    "\n",
    "    # Generate translated and recovered waveforms for cycle BAB\n",
    "    with torch.no_grad():\n",
    "        fake_A = netG_B2A(real_B)  # Simulated to data\n",
    "        recovered_B = netG_A2B(fake_A)  # Data back to simulated\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    real_Bs = real_B[0, 0, :].cpu().numpy()\n",
    "    fake_As = fake_A[0, 0, :].cpu().numpy()\n",
    "    recovered_Bs = recovered_B[0, 0, :].cpu().numpy()\n",
    "    real_As = real_A[0, 0, :].cpu().numpy()  # Reference target data pulse\n",
    "\n",
    "    # Plotting the cycle BAB\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(time, real_Bs, label='Simulated Pulse (Real B)', color='#0072BD', linestyle='-')\n",
    "    plt.plot(time, fake_As, label='Translated Pulse (Fake A)', color='#D95319', linestyle='--')\n",
    "    plt.plot(time, recovered_Bs, label='Recovered Pulse (Recovered B)', color='#7E2F8E', linestyle='-.')\n",
    "    plt.plot(time, real_As, label='Target Data Pulse (Real A)', color='#4DBEEE', linestyle=':')\n",
    "    plt.title(\"Cycle BAB: Simulated -> Data -> Simulated\")\n",
    "    plt.xlabel('Time [ns]')\n",
    "    plt.ylabel('Normalized Pulses')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"figs/result_comp_cycle_BAB.png\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_cycle_ABA(netG_A2B, netG_B2A, real_A, real_B, DEVICE):\n",
    "    # Initialize to store one cycle of the waveform transformation for ABA cycle\n",
    "    time = np.linspace(0, 799, 800)  # Time axis for the waveforms\n",
    "\n",
    "    # Generate translated and recovered waveforms for cycle ABA\n",
    "    with torch.no_grad():\n",
    "        fake_B = netG_A2B(real_A)  # Data to simulated\n",
    "        recovered_A = netG_B2A(fake_B)  # Simulated back to data\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    real_As = real_A[0, 0, :].cpu().numpy()\n",
    "    fake_Bs = fake_B[0, 0, :].cpu().numpy()\n",
    "    recovered_As = recovered_A[0, 0, :].cpu().numpy()\n",
    "    real_Bs = real_B[0, 0, :].cpu().numpy()  # Reference target simulated pulse\n",
    "\n",
    "    # Plotting the cycle ABA\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(time, real_As, label='Original Pulse (Real A)', color='#4DBEEE', linestyle='-')\n",
    "    plt.plot(time, fake_Bs, label='Simulated Pulse (Fake B)', color='#77AC30', linestyle='--')\n",
    "    plt.plot(time, recovered_As, label='Recovered Pulse (Recovered A)', color='#A2142F', linestyle='-.')\n",
    "    plt.plot(time, real_Bs, label='Target Simulated Pulse (Real B)', color='#0072BD', linestyle=':')\n",
    "    plt.title(\"Cycle ABA: Data -> Simulated -> Data\")\n",
    "    plt.xlabel('Time [ns]')\n",
    "    plt.ylabel('Normalized Pulses')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"figs/result_comp_cycle_ABA.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Extract a single sample from the train_loader\n",
    "real_A, real_B, _, _ = next(iter(train_loader))\n",
    "real_A = real_A.to(DEVICE)\n",
    "real_B = real_B.to(DEVICE)\n",
    "\n",
    "# Call the functions using the same pulses for both cycles\n",
    "plot_cycle_BAB(IATN, ATN, real_A, real_B, DEVICE)\n",
    "plot_cycle_ABA(IATN, ATN, real_A, real_B, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38595955-2780-48c2-8d20-1063883c1dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cycle_BAB_with_style(netG_A2B, netG_B2A, train_loader, DEVICE, sample_rate=5, eng_peak=\"eng_peak\", eng_peak_load=\"eng_peak_load\"):\n",
    "    # Initialize lists to store waveforms\n",
    "    real_Bs, fake_As, recovered_Bs, real_As = [], [], [], []\n",
    "\n",
    "    time = np.linspace(0, 799, 800)\n",
    "    cut = time > 5  \n",
    "\n",
    "    # Loop over a fixed number of samples\n",
    "    for _ in range(sample_rate):\n",
    "        real_A, real_B, a, b = next(iter(train_loader))\n",
    "        real_A = real_A.to(DEVICE)\n",
    "        real_B = real_B.to(DEVICE)\n",
    "\n",
    "        # Generate and recover\n",
    "        with torch.no_grad():\n",
    "            fake_A = netG_B2A(real_B)\n",
    "            recovered_B = netG_A2B(fake_A)\n",
    "\n",
    "        # Collect waveforms\n",
    "        real_Bs.append(real_B[0, 0, :].cpu().numpy())\n",
    "        fake_As.append(fake_A[0, 0, :].cpu().numpy())\n",
    "        recovered_Bs.append(recovered_B[0, 0, :].cpu().numpy())\n",
    "        real_As.append(real_A[0, 0, :].cpu().numpy())\n",
    "\n",
    "       # Plotting\n",
    "    colors = {\n",
    "        \"real_B\": \"#0072BD\",  # bright blue\n",
    "        \"fake_A\": \"#D95319\",  # bright orange\n",
    "        \"recovered_B\": \"#7E2F8E\",  # purple\n",
    "    }\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 5))  \n",
    "    titles = [\"Simulated Pulses\", \"Translated Pulses\", \"Recovered Pulses\"]\n",
    "    waveform_lists = [real_Bs, fake_As, recovered_Bs]\n",
    "    color_keys = [\"real_B\", \"fake_A\", \"recovered_B\"]\n",
    "\n",
    "    for ax, title, waveforms, color_key in zip(axs, titles, waveform_lists, color_keys):\n",
    "        for i in range(sample_rate):\n",
    "            ax.plot(time[cut], waveforms[i][cut], color=colors[color_key], label=title if i == 0 else \"\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Time [ns]')\n",
    "        ax.set_ylabel('Normlized Pulses')\n",
    "        # ax.legend(loc='upper right')\n",
    "\n",
    "    fig.tight_layout()  # Adjust subplots to fit into the figure area.\n",
    "    plt.savefig(\"figs/result_comp_1x3_cycle_BAB.png\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_cycle_BAB_with_style(IATN, ATN, train_loader, DEVICE, sample_rate=10, eng_peak=\"SEP\", eng_peak_load=\"DEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753b965-7abd-4a2a-9b46-5e8862338638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def plot_cycle_ABA_with_style(netG_A2B, netG_B2A, train_loader, DEVICE, sample_rate=5, eng_peak=\"eng_peak\", eng_peak_load=\"eng_peak_load\"):\n",
    "    # Initialize lists to store waveforms\n",
    "    real_As, fake_Bs, recovered_As = [], [], []\n",
    "\n",
    "    time = np.linspace(0, 799, 800)\n",
    "    cut = time > 5  \n",
    "\n",
    "    # Loop over a fixed number of samples\n",
    "    for _ in range(sample_rate):\n",
    "        real_A, real_B,a,b = next(iter(train_loader))\n",
    "        real_A = real_A.to(DEVICE)\n",
    "        real_B = real_B.to(DEVICE)\n",
    "\n",
    "        # Generate and recover\n",
    "        with torch.no_grad():\n",
    "            fake_B = netG_A2B(real_A)\n",
    "            recovered_A = netG_B2A(fake_B)\n",
    "\n",
    "        # Collect waveforms\n",
    "        real_As.append(real_A[0, 0, :].cpu().numpy())\n",
    "        fake_Bs.append(fake_B[0, 0, :].cpu().numpy())\n",
    "        recovered_As.append(recovered_A[0, 0, :].cpu().numpy())\n",
    "\n",
    "    # Plotting\n",
    "    colors = {\n",
    "        \"real_A\": \"#0072BD\",  # bright blue\n",
    "        \"fake_B\": \"#D95319\",  # bright orange\n",
    "        \"recovered_A\": \"#7E2F8E\",  # purple\n",
    "    }\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    titles = [\"Detector Pulses\", \"Translated Pulses\", \"Recovered Pulses\"]\n",
    "    waveform_lists = [real_As, fake_Bs, recovered_As]\n",
    "    color_keys = [\"real_A\", \"fake_B\", \"recovered_A\"]\n",
    "\n",
    "    for ax, title, waveforms, color_key in zip(axs, titles, waveform_lists, color_keys):\n",
    "        for i in range(sample_rate):\n",
    "            ax.plot(time[cut], waveforms[i][cut], color=colors[color_key], label=title if i == 0 else \"\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Time [ns]')\n",
    "        ax.set_ylabel('Normlized Pulses')\n",
    "        # ax.legend(loc='upper right')\n",
    "\n",
    "    fig.tight_layout()  # Adjust subplots to fit into the figure area.\n",
    "    plt.savefig(\"figs/result_comp_1x3_cycle_ABA.png\")\n",
    "    plt.show()\n",
    "\n",
    "plot_cycle_ABA_with_style(IATN, ATN, train_loader, DEVICE, sample_rate=10, eng_peak=\"DEP\", eng_peak_load=\"FEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2846e7-da04-46d1-9181-9dc6c9037de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3c420-f9bd-45bd-98f4-a585120a5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "# Define the WFDist class\n",
    "class WFDist(nn.Module):\n",
    "    '''\n",
    "    Waveform Distance, this is a special type of L1 loss which gives more weight to the\n",
    "    rising and falling edge of each pulse.\n",
    "    baseline(0,250) rising edge=(250,500), tail=(500,800)\n",
    "    '''\n",
    "    def __init__(self, baseline_weight, ris_edge_weight, tail_weight):\n",
    "        super(WFDist, self).__init__()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weight = torch.tensor(\n",
    "            [baseline_weight] * baseline_len +\n",
    "            [ris_edge_weight] * rising_edge_len +\n",
    "            [tail_weight] * tail_len\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        loss_out = 0.0\n",
    "        for i in range(x1.size(0)):\n",
    "            loss_out += self.criterion(x1[i].view(-1) * self.weight, x2[i].view(-1) * self.weight)\n",
    "        return loss_out / x1.size(0)\n",
    "\n",
    "# Function to plot the top 5 waveforms with the highest L1 loss in both categories\n",
    "def plot_top_waveforms(top_sim, top_translated):\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "    # Plot top 5 highest L1 loss waveforms for data vs. simulation\n",
    "    for i, (loss, real_wf, sim_wf) in enumerate(top_sim):\n",
    "        axs[0, i].plot(real_wf, label='Data')\n",
    "        axs[0, i].plot(sim_wf, label='Sim')\n",
    "        axs[0, i].set_title(f'Top {i+1} L1 Loss (Sim): {loss:.4f}')\n",
    "        axs[0, i].legend()\n",
    "        axs[0, i].grid(True)\n",
    "\n",
    "    # Plot top 5 highest L1 loss waveforms for data vs. translated\n",
    "    for i, (loss, real_wf, trans_wf) in enumerate(top_translated):\n",
    "        axs[1, i].plot(real_wf, label='Data')\n",
    "        axs[1, i].plot(trans_wf, label='Translated')\n",
    "        axs[1, i].set_title(f'Top {i+1} L1 Loss: {loss:.4f}')\n",
    "        axs[1, i].legend()\n",
    "        axs[1, i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "atn_loss_list = []  # Loss between data and translated simulated waveforms\n",
    "iatn_loss_list = []  # Loss between simulated and translated data waveforms\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "ATN.eval()\n",
    "IATN.eval()\n",
    "\n",
    "# Initialize the loss criterion\n",
    "criterion_valid = WFDist(baseline_weight, ris_edge_weight, tail_weight).to(DEVICE)\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    # Iterate over the data loader\n",
    "    for wf, wf_deconv, rawwf, x in tqdm(train_loader):\n",
    "        # Move input waveforms to the correct device\n",
    "        wf = wf.to(DEVICE)  # Real data\n",
    "        wf_deconv = wf_deconv.to(DEVICE)  # Simulated data\n",
    "\n",
    "        # Generate data-like waveforms using ATN\n",
    "        translated_sim = ATN(wf_deconv.float())\n",
    "\n",
    "        # Generate sim-like waveforms using IATN\n",
    "        translated_data = IATN(wf.float())\n",
    "\n",
    "        # Iterate over each waveform in the batch\n",
    "        for i in range(wf.size(0)):\n",
    "            real_wf = wf[i, 0]  # Real waveform\n",
    "            sim_wf = wf_deconv[i, 0]  # Simulated waveform\n",
    "            trans_sim_wf = translated_sim[i, 0]  # Translated simulated waveform\n",
    "            trans_data_wf = translated_data[i, 0]  # Translated data waveform\n",
    "\n",
    "            # Calculate the loss between real data and translated simulated waveform (ATN performance)\n",
    "            atn_loss = criterion_valid(real_wf.unsqueeze(0), trans_sim_wf.unsqueeze(0))\n",
    "            atn_loss_list.append((atn_loss.item(), real_wf.cpu().numpy(), trans_sim_wf.cpu().numpy()))\n",
    "\n",
    "            # Calculate the loss between simulated waveform and translated data waveform (IATN performance)\n",
    "            iatn_loss = criterion_valid(sim_wf.unsqueeze(0), trans_data_wf.unsqueeze(0))\n",
    "            iatn_loss_list.append((iatn_loss.item(), sim_wf.cpu().numpy(), trans_data_wf.cpu().numpy()))\n",
    "\n",
    "# Find the top 5 highest losses for both ATN and IATN\n",
    "top_atn_losses = heapq.nlargest(5, atn_loss_list, key=lambda x: x[0])\n",
    "top_iatn_losses = heapq.nlargest(5, iatn_loss_list, key=lambda x: x[0])\n",
    "\n",
    "# Plot the top 5 waveforms with the highest losses for ATN and IATN\n",
    "plot_top_waveforms(top_atn_losses, top_iatn_losses)\n",
    "\n",
    "# Calculate and print overall average losses\n",
    "average_atn_loss = sum(x[0] for x in atn_loss_list) / len(atn_loss_list) if atn_loss_list else 0\n",
    "average_iatn_loss = sum(x[0] for x in iatn_loss_list) / len(iatn_loss_list) if iatn_loss_list else 0\n",
    "\n",
    "print(f\"Average WFDist loss between data pulses and ATN-translated simulated pulses: {average_atn_loss}\")\n",
    "print(f\"Average WFDist loss between simulated pulses and IATN-translated data pulses: {average_iatn_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2c641-ad2b-4ca5-b8f0-830f86df29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the lists\n",
    "atn_losses = [x[0] for x in atn_loss_list]\n",
    "iatn_losses = [x[0] for x in iatn_loss_list]\n",
    "\n",
    "# Define the number of bins for the histograms\n",
    "num_bins = 25\n",
    "\n",
    "# Calculate histogram data for ATN losses\n",
    "atn_hist, atn_bin_edges = np.histogram(atn_losses, bins=num_bins)\n",
    "atn_top_bins_indices = np.argsort(atn_hist)[-10:]  # Indices of the top 10 most frequent bins\n",
    "\n",
    "# Calculate histogram data for IATN losses\n",
    "iatn_hist, iatn_bin_edges = np.histogram(iatn_losses, bins=num_bins)\n",
    "iatn_top_bins_indices = np.argsort(iatn_hist)[-10:]  # Indices of the top 10 most frequent bins\n",
    "\n",
    "# Plotting histograms for visualization\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histogram for ATN losses\n",
    "plt.hist(atn_losses, bins=num_bins, alpha=0.7, label='ATN Losses (Data - Translated Sim)', color='blue')\n",
    "\n",
    "# Histogram for IATN losses\n",
    "plt.hist(iatn_losses, bins=num_bins, alpha=0.7, label='IATN Losses (Sim - Translated Data)', color='orange')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Distribution of WFDist Losses for ATN and IATN')\n",
    "plt.xlabel('WFDist Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Set the number of samples to plot per bin\n",
    "num_samples_per_bin = 3  # Adjustable variable\n",
    "\n",
    "# Function to plot a few samples for the top 10 most frequent bins\n",
    "def plot_samples_from_bins(loss_list, bin_edges, top_bins_indices, label, input_type):\n",
    "    fig, axs = plt.subplots(5, 2, figsize=(15, 25))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for idx, bin_idx in enumerate(top_bins_indices):\n",
    "        # Get the bin range\n",
    "        bin_min = bin_edges[bin_idx]\n",
    "        bin_max = bin_edges[bin_idx + 1]\n",
    "        \n",
    "        # Extract samples within the current bin\n",
    "        samples_in_bin = [sample for loss, *sample in loss_list if bin_min <= loss < bin_max]\n",
    "        \n",
    "        # Plot up to num_samples_per_bin samples from each bin\n",
    "        for sample in samples_in_bin[:num_samples_per_bin]:\n",
    "            if input_type == 'ATN':\n",
    "                # Plot the data pulses that ATN is trying to match\n",
    "                axs[idx].plot(sample[0], label=f'Real Data (Bin [{bin_min:.2f}, {bin_max:.2f}])')\n",
    "            elif input_type == 'IATN':\n",
    "                # Plot the simulated pulses that IATN is trying to match\n",
    "                axs[idx].plot(sample[0], label=f'Simulated Data (Bin [{bin_min:.2f}, {bin_max:.2f}])')\n",
    "            axs[idx].legend()\n",
    "            axs[idx].grid(True)\n",
    "    \n",
    "    plt.suptitle(f'Sample Waveforms from Top 10 Most Frequent Bins - {label}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting samples from top 10 bins for ATN and IATN\n",
    "plot_samples_from_bins(atn_loss_list, atn_bin_edges, atn_top_bins_indices, label='ATN Losses', input_type='ATN')\n",
    "plot_samples_from_bins(iatn_loss_list, iatn_bin_edges, iatn_top_bins_indices, label='IATN Losses', input_type='IATN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc330e0-1877-4a5c-895d-44a65969b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set the group size for combining time points\n",
    "group_size = 20  # Group by 20 time points, adjustable variable\n",
    "\n",
    "# Use only the first 500 entries for debugging purposes\n",
    "subset_size = len(atn_loss_list)\n",
    "atn_loss_subset = atn_loss_list[:subset_size]\n",
    "iatn_loss_subset = iatn_loss_list[:subset_size]\n",
    "\n",
    "# Extract the waveform differences (absolute losses) for ATN and IATN\n",
    "atn_diff = [np.abs(real - trans_sim) for _, real, trans_sim in atn_loss_subset]\n",
    "iatn_diff = [np.abs(sim - trans_data) for _, sim, trans_data in iatn_loss_subset]\n",
    "\n",
    "# Convert to numpy arrays\n",
    "atn_diff = np.array(atn_diff)  # Shape: (500, num_time_points)\n",
    "iatn_diff = np.array(iatn_diff)  # Shape: (500, num_time_points)\n",
    "\n",
    "# Transpose to group the data by time points\n",
    "atn_diff_transposed = atn_diff.T  # Shape: (num_time_points, 500)\n",
    "iatn_diff_transposed = iatn_diff.T  # Shape: (num_time_points, 500)\n",
    "\n",
    "# Group the data by the specified group size\n",
    "grouped_atn_diffs = [\n",
    "    np.mean(atn_diff_transposed[i:i + group_size], axis=0)\n",
    "    for i in range(0, atn_diff_transposed.shape[0], group_size)\n",
    "]\n",
    "\n",
    "grouped_iatn_diffs = [\n",
    "    np.mean(iatn_diff_transposed[i:i + group_size], axis=0)\n",
    "    for i in range(0, iatn_diff_transposed.shape[0], group_size)\n",
    "]\n",
    "\n",
    "# Plotting box plots for ATN losses grouped by time points\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.boxplot(grouped_atn_diffs, patch_artist=True)\n",
    "plt.title('Box Plot of ATN Losses Grouped by Time Points (First 500 Samples)')\n",
    "plt.xlabel('Grouped Time Points')\n",
    "plt.ylabel('WFDist Loss (Data - Translated Sim)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting box plots for IATN losses grouped by time points\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.boxplot(grouped_iatn_diffs, patch_artist=True)\n",
    "plt.title('Box Plot of IATN Losses Grouped by Time Points (First 500 Samples)')\n",
    "plt.xlabel('Grouped Time Points')\n",
    "plt.ylabel('WFDist Loss (Sim - Translated Data)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780713e-daca-440c-a0ad-907f36c3df8f",
   "metadata": {},
   "source": [
    "Code below does a direct comparions of sim verses data and tranlated pulses verses data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645a059-e70c-4eaa-a072-e1abfbd55a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f90ae2-1bc8-483b-a9b5-ad85b931d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WFDist(nn.Module):\n",
    "    '''\n",
    "    Waveform Distance, this is a special type of L1 loss which gives more weight to the\n",
    "    rising and falling edge of each pulse\n",
    "    baseline(0,250) rising edge=(250,500), tail=(500,800)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, baseline_weight, ris_edge_weight, tail_weight):\n",
    "        super(WFDist, self).__init__()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weight = torch.tensor([baseline_weight]*baseline_len+[ris_edge_weight]*rising_edge_len+[tail_weight]*tail_len).to(DEVICE)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        loss_out = 0.0\n",
    "        for i in range(x1.size(0)):\n",
    "            loss_out += self.criterion(x1[i].view(-1)*self.weight, x2[i].view(-1)*self.weight)#/self.weight.sum()\n",
    "        return loss_out/x1.size(0)\n",
    "\n",
    "import heapq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot the top 5 waveforms with the highest L1 loss in both categories\n",
    "def plot_top_waveforms(top_sim, top_translated):\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "    # Plot top 5 highest L1 loss waveforms for data vs. simulation\n",
    "    for i, (loss, real_wf, sim_wf) in enumerate(top_sim):\n",
    "        axs[0, i].plot(real_wf, label='Data')\n",
    "        axs[0, i].plot(sim_wf, label='Sim')\n",
    "        axs[0, i].set_title(f'Top {i+1} L1 Loss (Sim): {loss:.4f}')\n",
    "        axs[0, i].legend()\n",
    "        axs[0, i].grid(True)\n",
    "\n",
    "    # Plot top 5 highest L1 loss waveforms for data vs. translated\n",
    "    for i, (loss, real_wf, trans_wf) in enumerate(top_translated):\n",
    "        axs[1, i].plot(real_wf, label='Data')\n",
    "        axs[1, i].plot(trans_wf, label='Translated')\n",
    "        axs[1, i].set_title(f'Top {i+1} L1 Loss: {loss:.4f}')\n",
    "        axs[1, i].legend()\n",
    "        axs[1, i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Initialize lists to store loss values and waveforms\n",
    "l1_data_sim = []  # L1 loss between data pulses and simulation pulses\n",
    "l1_data_translated = []  # L1 loss between data pulses and translated pulses\n",
    "\n",
    "# Set the model to evaluation mode and disable gradient calculation\n",
    "ATN.eval()\n",
    "criterion_valid = WFDist(baseline_weight, ris_edge_weight, tail_weight).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    # Iterate over the data loader\n",
    "    for wf, wf_deconv, rawwf, x in tqdm(train_loader):\n",
    "        # Move input waveforms to the correct device\n",
    "        wf = wf.to(DEVICE)\n",
    "        wf_deconv = wf_deconv.to(DEVICE)\n",
    "\n",
    "        # Generate translated waveforms using the model\n",
    "        gan_wf = ATN(wf_deconv.float())\n",
    "\n",
    "        # Iterate over each waveform in the batch\n",
    "        for i in range(wf.size(0)):\n",
    "            # Get the real waveform, simulated waveform, and translated waveform\n",
    "            real_wf = wf[i, 0]  # Real waveform tensor on DEVICE\n",
    "            sim_wf = wf_deconv[i, 0]  # Simulated waveform tensor on DEVICE\n",
    "            transfer_wf = gan_wf[i, 0]  # Translated waveform tensor on DEVICE\n",
    "\n",
    "            # Calculate the L1 loss between data and simulation waveforms individually\n",
    "            l1_sim = criterion_valid(real_wf.unsqueeze(0), sim_wf.unsqueeze(0))\n",
    "            l1_data_sim.append((l1_sim.item(), real_wf.cpu().numpy(), sim_wf.cpu().numpy()))\n",
    "\n",
    "            # Calculate the L1 loss between data and translated waveforms individually\n",
    "            l1_translated = criterion_valid(real_wf.unsqueeze(0), transfer_wf.unsqueeze(0))\n",
    "            l1_data_translated.append((l1_translated.item(), real_wf.cpu().numpy(), transfer_wf.cpu().numpy()))\n",
    "\n",
    "# Find the top 5 highest losses using heapq\n",
    "top_sim = heapq.nlargest(5, l1_data_sim, key=lambda x: x[0])\n",
    "top_translated = heapq.nlargest(5, l1_data_translated, key=lambda x: x[0])\n",
    "\n",
    "# Plotting the top 5 waveforms with the highest L1 loss for both categories\n",
    "plot_top_waveforms(top_sim, top_translated)\n",
    "\n",
    "# Calculate overall average L1 losses\n",
    "average_l1_data_sim = sum(x[0] for x in l1_data_sim) / len(l1_data_sim) if l1_data_sim else 0\n",
    "average_l1_data_translated = sum(x[0] for x in l1_data_translated) / len(l1_data_translated) if l1_data_translated else 0\n",
    "\n",
    "# Print the average L1 losses\n",
    "print(f\"L1 loss between data pulses and simulation pulses: {average_l1_data_sim}\")\n",
    "print(f\"L1 loss between data pulses and translated pulses: {average_l1_data_translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14892dc4-fa1a-4242-9e9c-5350408e3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(average_l1_data_translated-average_l1_data_sim)*100/average_l1_data_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c71d6-9830-4cd3-aae1-5728c116f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract L1 loss values from l1_data_sim and l1_data_translated\n",
    "l1_sim_losses = [x[0] for x in l1_data_sim]\n",
    "l1_translated_losses = [x[0] for x in l1_data_translated]\n",
    "\n",
    "# Define the number of bins for the histograms\n",
    "num_bins = 50\n",
    "\n",
    "# Plotting histograms for visualization\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histogram for L1 losses between data and simulated pulses\n",
    "plt.hist(l1_sim_losses, bins=num_bins, alpha=0.7, label='L1 Losses (Data vs. Sim)', color='blue')\n",
    "\n",
    "# Histogram for L1 losses between data and translated pulses\n",
    "plt.hist(l1_translated_losses, bins=num_bins, alpha=0.7, label='L1 Losses (Data vs. Translated)', color='orange')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Distribution of WFDist Losses for Data vs. Sim and Data vs. Translated')\n",
    "plt.xlabel('WFDist Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701edc0-b066-4812-a84d-fedc28c8c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set the group size for combining time points\n",
    "group_size = 10  # You can change this variable to adjust the grouping\n",
    "\n",
    "# Use only the first 500 entries for debugging purposes\n",
    "subset_size = 500\n",
    "l1_data_sim_subset = l1_data_sim[:subset_size]\n",
    "l1_data_translated_subset = l1_data_translated[:subset_size]\n",
    "\n",
    "# Extract the L1 loss differences from the subsets\n",
    "# Calculate the absolute differences at each time point between real and simulated/translated waveforms\n",
    "diff_sim_subset = [np.abs(real - sim) for _, real, sim in l1_data_sim_subset]  # Differences for simulated waveforms\n",
    "diff_translated_subset = [np.abs(real - trans) for _, real, trans in l1_data_translated_subset]  # Differences for translated waveforms\n",
    "\n",
    "# Convert to numpy arrays\n",
    "diff_sim_subset = np.array(diff_sim_subset)  # Shape: (500, num_time_points)\n",
    "diff_translated_subset = np.array(diff_translated_subset)  # Shape: (500, num_time_points)\n",
    "\n",
    "# Calculate the difference between the two losses for each waveform\n",
    "diff_combined_subset = diff_sim_subset - diff_translated_subset  # Shape: (500, num_time_points)\n",
    "\n",
    "# Transpose to have time points as columns for box plotting\n",
    "diff_combined_transposed_subset = diff_combined_subset.T  # Shape: (num_time_points, 500)\n",
    "\n",
    "# Group the data by the specified group size\n",
    "grouped_diffs = [\n",
    "    np.mean(diff_combined_transposed_subset[i:i + group_size], axis=0)\n",
    "    for i in range(0, diff_combined_transposed_subset.shape[0], group_size)\n",
    "]\n",
    "\n",
    "# Plotting box plots for each group of time points\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.boxplot(grouped_diffs, patch_artist=True)\n",
    "plt.title('Box Plot of L1 Loss Differences Between Simulated and Translated Waveforms (Grouped by 20 Time Points)')\n",
    "plt.xlabel('Grouped Time Points')\n",
    "plt.ylabel('L1 Loss Difference (Simulated - Translated)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534ab67-fea9-447f-986f-c423a7d40054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize arrays to store per-time L1 losses\n",
    "l1_data_sim_time = np.zeros(SEQ_LEN)  # Sum of L1 loss at each time point across all pulses for data vs. simulation\n",
    "l1_data_translated_time = np.zeros(SEQ_LEN)  # Sum of L1 loss at each time point across all pulses for data vs. translated\n",
    "count_sim = np.zeros(SEQ_LEN)  # Count of valid pulses at each time point for data vs. simulation\n",
    "count_translated = np.zeros(SEQ_LEN)  # Count of valid pulses at each time point for data vs. translated\n",
    "\n",
    "# Iterate over all data points\n",
    "for loss, real_wf, sim_wf in l1_data_sim:\n",
    "    per_time_loss = np.abs(real_wf - sim_wf)  # L1 loss at each time point\n",
    "    l1_data_sim_time += per_time_loss\n",
    "    count_sim += 1  # Increment count\n",
    "\n",
    "for loss, real_wf, trans_wf in l1_data_translated:\n",
    "    per_time_loss = np.abs(real_wf - trans_wf)  # L1 loss at each time point\n",
    "    l1_data_translated_time += per_time_loss\n",
    "    count_translated += 1  # Increment count\n",
    "\n",
    "# Normalize by the count to get average loss per time point\n",
    "average_l1_data_sim_time = l1_data_sim_time / count_sim\n",
    "average_l1_data_translated_time = l1_data_translated_time / count_translated\n",
    "\n",
    "# Plotting the average L1 loss over time (pulse timeline) for both simulations and translations\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(average_l1_data_sim_time, label='Simulated vs Data', color='red', alpha=0.5)\n",
    "plt.plot(average_l1_data_translated_time, label='Translated vs Data', color='blue', alpha=0.5)\n",
    "plt.title('Average L1 Loss Over Pulse Time')\n",
    "plt.xlabel('Time (Pulse Sample Index)')\n",
    "plt.ylabel('Average L1 Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Identifying where the largest errors occur in the pulse timeline\n",
    "max_loss_indices_sim = np.argsort(-average_l1_data_sim_time)[:10]  # Indices of top 10 highest loss times for sim vs data\n",
    "max_loss_indices_translated = np.argsort(-average_l1_data_translated_time)[:10]  # Indices of top 10 highest loss times for translated vs data\n",
    "\n",
    "print(\"Top 10 time indices with highest L1 loss for Simulated vs Data:\", max_loss_indices_sim)\n",
    "print(\"Top 10 time indices with highest L1 loss for Translated vs Data:\", max_loss_indices_translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3beb2aa-fae1-45e3-a64d-b8112dead8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Define the WFDist class\n",
    "class WFDist(nn.Module):\n",
    "    '''\n",
    "    Waveform Distance, this is a special type of L1 loss which gives more weight to the\n",
    "    rising and falling edge of each pulse.\n",
    "    baseline(0,250) rising edge=(250,500), tail=(500,800)\n",
    "    '''\n",
    "    def __init__(self, baseline_weight, ris_edge_weight, tail_weight):\n",
    "        super(WFDist, self).__init__()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weight = torch.tensor(\n",
    "            [baseline_weight] * baseline_len +\n",
    "            [ris_edge_weight] * rising_edge_len +\n",
    "            [tail_weight] * tail_len\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        loss_out = 0.0\n",
    "        for i in range(x1.size(0)):\n",
    "            loss_out += self.criterion(x1[i].view(-1) * self.weight, x2[i].view(-1) * self.weight)\n",
    "        return loss_out / x1.size(0)\n",
    "\n",
    "# Function to normalize waveform\n",
    "def normalize_waveform(wf):\n",
    "    \"\"\"Normalize waveform by dividing by the average of the last norm_samples samples and shifting the waveform \n",
    "       so that the average of the first 200 samples is zero.\"\"\"\n",
    "    tail_mean = np.mean(wf[-norm_samples:])\n",
    "    if tail_mean != 0:\n",
    "        normalized_wf = wf * norm_tail_height / tail_mean\n",
    "    else:\n",
    "        normalized_wf = wf  # Avoid division by zero\n",
    "    first_200_mean = np.mean(normalized_wf[:200])\n",
    "    normalized_wf = normalized_wf - first_200_mean\n",
    "    return normalized_wf\n",
    "\n",
    "# Function to transform waveform based on tp0\n",
    "def transform_2(wf):\n",
    "    \"\"\"Transform waveform by padding based on tp0 and then normalizing.\"\"\"\n",
    "    wf = np.array(wf)\n",
    "    tp0 = int(round(calculate_tn(real_wf, t_n)))\n",
    "    left_padding = max(LSPAN - tp0, 0)\n",
    "    right_padding = max((RSPAN + tp0) - len(wf), 0)\n",
    "    wf_padded = np.pad(wf, (left_padding, right_padding), mode='edge')\n",
    "    tp0_adjusted = tp0 + left_padding\n",
    "    wf_sliced = wf_padded[(tp0_adjusted - LSPAN):(tp0_adjusted + RSPAN)]\n",
    "    wf_normalized = normalize_waveform(wf_sliced)\n",
    "    return wf_normalized\n",
    "\n",
    "# Function to plot the top 5 waveforms with the highest L1 loss in both categories\n",
    "def plot_top_waveforms(top_sim, top_translated):\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "    # Plot top 5 highest L1 loss waveforms for data vs. simulation\n",
    "    for i, (loss, real_wf, sim_wf) in enumerate(top_sim):\n",
    "        axs[0, i].plot(real_wf, label='Data')\n",
    "        axs[0, i].plot(sim_wf, label='Sim')\n",
    "        axs[0, i].set_title(f'Top {i+1} L1 Loss (Sim): {loss:.4f}')\n",
    "        axs[0, i].legend()\n",
    "        axs[0, i].grid(True)\n",
    "\n",
    "    # Plot top 5 highest L1 loss waveforms for data vs. translated\n",
    "    for i, (loss, real_wf, trans_wf) in enumerate(top_translated):\n",
    "        axs[1, i].plot(real_wf, label='Data')\n",
    "        axs[1, i].plot(trans_wf, label='Translated')\n",
    "        axs[1, i].set_title(f'Top {i+1} L1 Loss: {loss:.4f}')\n",
    "        axs[1, i].legend()\n",
    "        axs[1, i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Initialize lists to store loss values and waveforms\n",
    "l1_data_sim = []  # L1 loss between data pulses and simulation pulses\n",
    "l1_data_translated = []  # L1 loss between data pulses and translated pulses\n",
    "\n",
    "# Set the model to evaluation mode and disable gradient calculation\n",
    "ATN.eval()\n",
    "criterion_valid = WFDist(baseline_weight, ris_edge_weight, tail_weight).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    # Iterate over the data loader\n",
    "    for wf, wf_deconv, rawwf, x in tqdm(train_loader):\n",
    "        # Move input waveforms to the correct device\n",
    "        wf = wf.to(DEVICE)\n",
    "        wf_deconv = wf_deconv.to(DEVICE)\n",
    "\n",
    "        # Generate translated waveforms using the model\n",
    "        gan_wf = ATN(wf_deconv.float())\n",
    "\n",
    "        # Iterate over each waveform in the batch\n",
    "        for i in range(wf.size(0)):\n",
    "            # Get the real waveform, simulated waveform, and translated waveform\n",
    "            real_wf = wf[i, 0].cpu().numpy()  # Real waveform tensor on DEVICE\n",
    "            sim_wf = wf_deconv[i, 0].cpu().numpy()  # Simulated waveform tensor on DEVICE\n",
    "            transfer_wf = gan_wf[i, 0].cpu().numpy()  # Translated waveform tensor on DEVICE\n",
    "\n",
    "            # Transform the waveforms using the transform function\n",
    "            data_transformed_wf = transform_2(real_wf)\n",
    "            sim_transformed_wf = transform_2(sim_wf)\n",
    "            translated_transformed_wf = transform_2(transfer_wf)\n",
    "\n",
    "            # Convert the transformed waveforms back to tensors for loss calculation\n",
    "            data_transformed_tensor = torch.tensor(data_transformed_wf).to(DEVICE).unsqueeze(0)\n",
    "            sim_transformed_tensor = torch.tensor(sim_transformed_wf).to(DEVICE).unsqueeze(0)\n",
    "            translated_transformed_tensor = torch.tensor(translated_transformed_wf).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "            # Calculate the L1 loss between data and simulation waveforms individually\n",
    "            l1_sim = criterion_valid(data_transformed_tensor, sim_transformed_tensor)\n",
    "            l1_data_sim.append((l1_sim.item(), data_transformed_wf, sim_transformed_wf))\n",
    "\n",
    "            # Calculate the L1 loss between data and translated waveforms individually\n",
    "            l1_translated = criterion_valid(data_transformed_tensor, translated_transformed_tensor)\n",
    "            l1_data_translated.append((l1_translated.item(), data_transformed_wf, translated_transformed_wf))\n",
    "\n",
    "# Find the top 5 highest losses using heapq\n",
    "top_sim = heapq.nlargest(5, l1_data_sim, key=lambda x: x[0])\n",
    "top_translated = heapq.nlargest(5, l1_data_translated, key=lambda x: x[0])\n",
    "\n",
    "# Plotting the top 5 waveforms with the highest L1 loss for both categories\n",
    "plot_top_waveforms(top_sim, top_translated)\n",
    "\n",
    "# Calculate overall average L1 losses\n",
    "average_l1_data_sim = sum(x[0] for x in l1_data_sim) / len(l1_data_sim) if l1_data_sim else 0\n",
    "average_l1_data_translated = sum(x[0] for x in l1_data_translated) / len(l1_data_translated) if l1_data_translated else 0\n",
    "\n",
    "# Print the average L1 losses\n",
    "print(f\"L1 loss between data pulses and simulation pulses: {average_l1_data_sim}\")\n",
    "print(f\"L1 loss between data pulses and translated pulses: {average_l1_data_translated}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f2573-0cca-4e14-a3c6-19b4009a8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "\n",
    "# class WFDist(nn.Module):\n",
    "#     '''\n",
    "#     Waveform Distance: A special L1 loss that gives more weight to the rising and falling edges of each pulse\n",
    "#     baseline(0,250), rising edge=(250,500), tail=(500,800)\n",
    "#     '''\n",
    "#     def __init__(self, baseline_weight, ris_edge_weight, tail_weight):\n",
    "#         super(WFDist, self).__init__()\n",
    "#         self.criterion = nn.L1Loss(reduction='none')  # 'none' to manually apply weights\n",
    "#         # Save the initial weight distribution without setting the length\n",
    "#         self.baseline_weight = baseline_weight\n",
    "#         self.ris_edge_weight = ris_edge_weight\n",
    "#         self.tail_weight = tail_weight\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         # Dynamically create the weight tensor based on the current length of the input\n",
    "#         length = x1.view(-1).size(0)\n",
    "#         baseline_len = min(250, length)  # Ensure that baseline_len doesn't exceed the input size\n",
    "#         ris_edge_len = min(500, length - baseline_len)\n",
    "#         tail_len = max(0, length - baseline_len - ris_edge_len)\n",
    "#         weight = torch.tensor(\n",
    "#             [self.baseline_weight] * baseline_len +\n",
    "#             [self.ris_edge_weight] * ris_edge_len +\n",
    "#             [self.tail_weight] * tail_len\n",
    "#         ).to(x1.device)\n",
    "        \n",
    "#         # Compute weighted L1 loss\n",
    "#         loss_out = self.criterion(x1.view(-1), x2.view(-1)) * weight\n",
    "#         return loss_out.sum() / weight.sum()  # Normalize by the sum of weights\n",
    "\n",
    "# def smooth_waveform(wf, window_size=5):\n",
    "#     \"\"\"Apply a simple moving average filter to smooth the waveform.\"\"\"\n",
    "#     return np.convolve(wf, np.ones(window_size) / window_size, mode='same')\n",
    "\n",
    "# # Function to calculate L1 loss between data pulses, simulation pulses, and translated pulses\n",
    "# def calculate_l1_loss(data_loader, ATN, DEVICE):\n",
    "#     l1_data_sim = []  # L1 loss between data pulses and simulation pulses\n",
    "#     l1_data_translated = []  # L1 loss between data pulses and translated pulses\n",
    "\n",
    "#     # Set the model to evaluation mode and disable gradient calculation\n",
    "#     ATN.eval()\n",
    "#     criterion_valid = WFDist(baseline_weight, ris_edge_weight, tail_weight).to(DEVICE)\n",
    "#     window_size = 5  # Define window size used for smoothing\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         # Iterate over the data loader\n",
    "#         for wf, wf_deconv, rawwf, x in tqdm(data_loader):\n",
    "#             # Move input waveforms to the correct device\n",
    "#             wf = wf.to(DEVICE)\n",
    "#             wf_deconv = wf_deconv.to(DEVICE)\n",
    "            \n",
    "#             # Generate translated waveforms using the model\n",
    "#             gan_wf = ATN(wf_deconv.float())\n",
    "            \n",
    "#             # Iterate over each waveform in the batch\n",
    "#             for iwf in range(wf.size(0)):\n",
    "#                 # Get the real waveform, simulated waveform, and translated waveform\n",
    "#                 real_wf = wf[iwf, 0].cpu().numpy()  # Real waveform tensor on DEVICE\n",
    "#                 sim_wf = wf_deconv[iwf, 0].cpu().numpy()  # Simulated waveform tensor on DEVICE\n",
    "#                 transfer_wf = gan_wf[iwf, 0].cpu().numpy()  # Translated waveform tensor on DEVICE\n",
    "\n",
    "#                 # Apply smoothing to the waveforms\n",
    "#                 smooth_real_wf = smooth_waveform(real_wf, window_size)\n",
    "#                 smooth_sim_wf = smooth_waveform(sim_wf, window_size)\n",
    "#                 smooth_transfer_wf = smooth_waveform(transfer_wf, window_size)\n",
    "\n",
    "#                 # Trim the last window_size samples to avoid edge effects\n",
    "#                 trim_len = window_size\n",
    "#                 smooth_real_wf = smooth_real_wf[:-trim_len]\n",
    "#                 smooth_sim_wf = smooth_sim_wf[:-trim_len]\n",
    "#                 smooth_transfer_wf = smooth_transfer_wf[:-trim_len]\n",
    "\n",
    "#                 # Convert smoothed waveforms back to tensors and move them to the correct device\n",
    "#                 smooth_real_wf = torch.tensor(smooth_real_wf, device=DEVICE)\n",
    "#                 smooth_sim_wf = torch.tensor(smooth_sim_wf, device=DEVICE)\n",
    "#                 smooth_transfer_wf = torch.tensor(smooth_transfer_wf, device=DEVICE)\n",
    "\n",
    "#                 # Calculate the L1 loss between smoothed data and simulation waveforms\n",
    "#                 l1_sim = criterion_valid(smooth_real_wf, smooth_sim_wf)\n",
    "#                 l1_data_sim.append((l1_sim.item(), smooth_real_wf.cpu().numpy(), smooth_sim_wf.cpu().numpy()))\n",
    "\n",
    "#                 # Calculate the L1 loss between smoothed data and translated waveforms\n",
    "#                 l1_translated = criterion_valid(smooth_real_wf, smooth_transfer_wf)\n",
    "#                 l1_data_translated.append((l1_translated.item(), smooth_real_wf.cpu().numpy(), smooth_transfer_wf.cpu().numpy()))\n",
    "\n",
    "\n",
    "#     # Plot an example of smoothed vs. original waveforms\n",
    "#     plot_example_smoothing(real_wf, smooth_real_wf.cpu().numpy())\n",
    "\n",
    "#     # Sort the losses to get the top 5 highest losses for both categories\n",
    "#     l1_data_sim.sort(reverse=True, key=lambda x: x[0])\n",
    "#     l1_data_translated.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "#     # Extract the top 5 waveforms with the highest losses\n",
    "#     top_sim = l1_data_sim[:5]\n",
    "#     top_translated = l1_data_translated[:5]\n",
    "\n",
    "#     # Plotting the top 5 waveforms with the highest L1 loss for both categories\n",
    "#     plot_top_waveforms(top_sim, top_translated)\n",
    "\n",
    "#     # Calculate overall average L1 losses\n",
    "#     average_l1_data_sim = sum(x[0] for x in l1_data_sim) / len(l1_data_sim) if l1_data_sim else 0\n",
    "#     average_l1_data_translated = sum(x[0] for x in l1_data_translated) / len(l1_data_translated) if l1_data_translated else 0\n",
    "    \n",
    "#     return average_l1_data_sim, average_l1_data_translated\n",
    "\n",
    "# def plot_example_smoothing(original_wf, smoothed_wf):\n",
    "#     \"\"\"\n",
    "#     Plot an example of an original waveform and its smoothed version.\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(original_wf, label='Original Waveform', color='blue', linewidth=0.7)\n",
    "#     plt.plot(smoothed_wf, label='Smoothed Waveform', color='red', linestyle='--', linewidth=1)\n",
    "#     plt.title('Example of Smoothing on a Waveform')\n",
    "#     plt.xlabel('Time Sample [ns]')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#     plt.minorticks_on()\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_top_waveforms(top_sim, top_translated):\n",
    "#     \"\"\"\n",
    "#     Function to plot the top 5 waveforms with the highest L1 loss in both categories.\n",
    "#     \"\"\"\n",
    "#     fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "#     # Plot top 5 highest L1 loss waveforms for data vs. simulation\n",
    "#     for i, (loss, real_wf, sim_wf) in enumerate(top_sim):\n",
    "#         axs[0, i].plot(real_wf, label='Data')\n",
    "#         axs[0, i].plot(sim_wf, label='Sim')\n",
    "#         axs[0, i].set_title(f'Top {i+1} L1 Loss (Sim): {loss:.4f}')\n",
    "#         axs[0, i].legend()\n",
    "#         axs[0, i].grid(True)\n",
    "\n",
    "#     # Plot top 5 highest L1 loss waveforms for data vs. translated\n",
    "#     for i, (loss, real_wf, trans_wf) in enumerate(top_translated):\n",
    "#         axs[1, i].plot(real_wf, label='Data')\n",
    "#         axs[1, i].plot(trans_wf, label='Translated')\n",
    "#         axs[1, i].set_title(f'Top {i+1} L1 Loss (Translated): {loss:.4f}')\n",
    "#         axs[1, i].legend()\n",
    "#         axs[1, i].grid(True)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Call the function with your train_loader\n",
    "# average_l1_data_sim, average_l1_data_translated = calculate_l1_loss(train_loader, ATN, DEVICE)\n",
    "\n",
    "# # Print the average L1 losses\n",
    "# print(f\"L1 loss between data pulses and simulation pulses: {average_l1_data_sim}\")\n",
    "# print(f\"L1 loss between data pulses and translated pulses: {average_l1_data_translated}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9960b-1387-4976-a539-089dcdc533f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Function to calculate MSE between data pulses, simulation pulses, and translated pulses\n",
    "# def calculate_mse(data_loader, ATN, DEVICE):\n",
    "#     mse_data_sim = []  # MSE between data pulses and simulation pulses\n",
    "#     mse_data_translated = []  # MSE between data pulses and translated pulses\n",
    "\n",
    "#     # Set the model to evaluation mode and disable gradient calculation\n",
    "#     ATN.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Iterate over the data loader\n",
    "#         for wf, wf_deconv, rawwf, x in tqdm(data_loader):\n",
    "#             # Move input waveforms to the correct device\n",
    "#             wf = wf.to(DEVICE)\n",
    "#             wf_deconv = wf_deconv.to(DEVICE)\n",
    "            \n",
    "#             # Generate translated waveforms using the model\n",
    "#             gan_wf = ATN(wf_deconv.float())\n",
    "            \n",
    "#             # Iterate over each waveform in the batch\n",
    "#             for iwf in range(wf.size(0)):\n",
    "#                 # Get the real waveform, simulated waveform, and translated waveform\n",
    "#                 real_wf = wf[iwf, 0]  # Real waveform tensor on DEVICE\n",
    "#                 sim_wf = wf_deconv[iwf, 0]  # Simulated waveform tensor on DEVICE\n",
    "#                 transfer_wf = gan_wf[iwf, 0]  # Translated waveform tensor on DEVICE\n",
    "                \n",
    "#                 # Calculate the MSE between data and simulation waveforms\n",
    "#                 mse_sim = F.mse_loss(real_wf, sim_wf)  \n",
    "#                 mse_data_sim.append(mse_sim.item())  \n",
    "\n",
    "#                 # Calculate the MSE between data and translated waveforms\n",
    "#                 mse_translated = F.mse_loss(real_wf, transfer_wf)  \n",
    "#                 mse_data_translated.append(mse_translated.item())\n",
    "\n",
    "#     # Calculate overall average MSEs\n",
    "#     average_mse_data_sim = sum(mse_data_sim) / len(mse_data_sim)\n",
    "#     average_mse_data_translated = sum(mse_data_translated) / len(mse_data_translated)\n",
    "    \n",
    "#     return average_mse_data_sim, average_mse_data_translated\n",
    "\n",
    "# # Call the function with your train_loader\n",
    "# average_mse_data_sim, average_mse_data_translated = calculate_mse(train_loader, ATN, DEVICE)\n",
    "\n",
    "# # Print the average MSEs\n",
    "# print(f\"Average MSE between data pulses and simulation pulses: {average_mse_data_sim}\")\n",
    "# print(f\"Average MSE between data pulses and translated pulses: {average_mse_data_translated}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2e069-09cc-48f3-95d2-600389e68e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9e270-669a-48c8-a7e6-6f85fe1c5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tp0(wf_blsub, cross):\n",
    "    \"\"\"\n",
    "    Calculate the tp_0 from a baseline-subtracted waveform by first finding the maximum time point\n",
    "    and then searching backwards to find when the waveform first crosses amplitude.\n",
    "    Parameters:\n",
    "    - wf_blsub (numpy.array): Baseline-subtracted waveform.\n",
    "    - cross (float) : Threshold for first crosses amplitude\n",
    "    Returns:\n",
    "    - tp_0 (float): Calculated time point zero.\n",
    "    \"\"\"\n",
    "    # Ensure wf is a numpy array\n",
    "    wf_blsub = np.asarray(wf_blsub)\n",
    "    tp_max = np.argmax(wf_blsub)\n",
    "    # Using np.where to find the first index meeting the condition\n",
    "    zero_crossings = np.where(wf_blsub[:tp_max] < cross)[0]\n",
    "    if zero_crossings.size > 0:\n",
    "        return zero_crossings[-1]  # Last crossing before max\n",
    "    return NaN  # Return NaN if no crossing found\n",
    "def calc_dt(wf, cross):\n",
    "    \"\"\"\n",
    "    Calculate the drift time as the difference between t99 and tp_0.\n",
    "    \"\"\"\n",
    "    t99 = calculate_tn(wf, 95)\n",
    "    tp_0 = calculate_tp0(wf, cross)\n",
    "    if np.isnan(t99) or np.isnan(tp_0):\n",
    "        return np.nan\n",
    "    return t99 - tp_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3baf6-08c1-4584-873b-7d1534e955ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = []\n",
    "gan_ts = []\n",
    "sim_ts = []\n",
    "data_ca = []\n",
    "gan_ca = []\n",
    "sim_ca = []\n",
    "data_wf= []\n",
    "siggen_wf= []\n",
    "dt_sim = []\n",
    "dt_data = []\n",
    "event_eng = []\n",
    "dt_gan = []\n",
    "i=0\n",
    "for wf, wf_deconv,rawwf,c in tqdm(train_loader):\n",
    "    # if i==20: #processs only 10 batches\n",
    "    #     break\n",
    "    bsize = wf.size(0)\n",
    "    gan_wf = ATN(wf_deconv.to(DEVICE).float())\n",
    "    for iwf in range(bsize):\n",
    "        datawf = wf[iwf,0].cpu().numpy().flatten()\n",
    "        siggenwf = wf_deconv[iwf,0].cpu().numpy().flatten()\n",
    "        transfer_wf = gan_wf[iwf,0].detach().cpu().numpy().flatten()\n",
    "        \n",
    "        ts.append(get_tail_slope(datawf))\n",
    "        gan_ts.append(get_tail_slope(transfer_wf))\n",
    "        sim_ts.append(get_tail_slope(siggenwf))\n",
    "        data_ca.append(calc_current_amplitude(datawf))\n",
    "        gan_ca.append(calc_current_amplitude(transfer_wf))\n",
    "        sim_ca.append(calc_current_amplitude(siggenwf))\n",
    "        siggen_wf.append(siggenwf)\n",
    "        data_wf.append(datawf)\n",
    "        dt_sim.append(calc_dt(siggenwf, 0.005))\n",
    "        dt_data.append(calc_dt(datawf, 0.005))\n",
    "        dt_gan.append(calc_dt(transfer_wf, 0.005))\n",
    "        event_eng.append(c[\"energy\"][iwf].cpu().numpy().flatten()[0])\n",
    "    #     plt.plot(datawf)\n",
    "    #     plt.axvline(calculate_tp0(datawf, 0.002), color='b', alpha=0.5, label='tp_0')\n",
    "    #     plt.axvline(calculate_tn(datawf, 99),color='r', alpha=0.5, label='tp_99')\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "    #     plt.plot(siggenwf)\n",
    "    #     plt.axvline(calculate_tp0(siggenwf,0.002), color='b', alpha=0.5, label='tp_0')\n",
    "    #     plt.axvline(calculate_tn(siggenwf,99),color='r', alpha=0.5, label='tp_99')\n",
    "    #     plt.legend()\n",
    "    #     break\n",
    "    # break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50e9e1-8823-4621-9837-7e4db85fc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = np.linspace(250, 2000,100)\n",
    "dt_sim_plot= np.array(dt_sim)*16\n",
    "dt_data_plot= np.array(dt_data)*16\n",
    "dt_gan_plot= np.array(dt_gan)*16\n",
    "\n",
    "plt.hist(dt_sim_plot, bins=db,histtype=\"step\",linewidth=2,density=False,color=\"tab:red\",alpha=0.6,label=\"Sim Pulse\")\n",
    "plt.hist(dt_data_plot, bins=db,histtype=\"step\",linewidth=2,density=False,color=\"tab:blue\",alpha=0.6,label=\"Data Pulse\")\n",
    "plt.hist(dt_gan_plot, bins=db,histtype=\"step\",linewidth=2,density=False,color=\"tab:green\",alpha=0.6,label=\"Tranlated Pulse\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"# of Events\")\n",
    "plt.xlabel(\"Drift time (ns)\")\n",
    "\n",
    "print(f\"Drift Time IoU between Detector Peak and Simulated Peak: {calculate_iou(dt_data_plot, dt_sim_plot, db, normed=False):.10f}\")\n",
    "print(f\"Drift Time IoU between Detector Peak and Translated Peak: {calculate_iou(dt_data_plot, dt_gan_plot, db, normed=False):.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a11b0-a18a-458d-9700-8301a2a2e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = np.linspace(-29.4e-5,-29.2e-5,50)\n",
    "log_status = False\n",
    "plt.hist(ts,bins=rg,histtype=\"step\",linewidth=2,log=log_status, color=\"#1f77b4\",label=\"Detector Pulse\", alpha=0.5)\n",
    "plt.hist(gan_ts,bins=rg,histtype=\"step\",linewidth=2,log=log_status, color=\"#ff7f0e\",label=\"Translated Pulse\", alpha=0.5)\n",
    "# plt.axvline(x=0,color=\"#2ca02c\",linewidth=3,label=\"Simulated Pulse\")\n",
    "# plt.xlim(-5,8)\n",
    "plt.legend()\n",
    "plt.ylabel(\"# of Events\")\n",
    "plt.xlabel(\"Tail Slope\")\n",
    "# plt.savefig(\"figs/tailslope.png\",dpi=200)\n",
    "# Calculate the histograms (with density=True to normalize the histograms)\n",
    "plt.legend()\n",
    "plt.xticks()  # Bigger tick labels\n",
    "plt.yticks()  # Bigger tick labels\n",
    "# plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.minorticks_on()\n",
    "plt.xticks(rotation=45)\n",
    "print(f\"Tail slope IoU between Detector Peak and Translated Peak: {calculate_iou(ts, gan_ts, rg, normed=False):.10f}\")\n",
    "\n",
    "# plt.savefig(f\"figs/{eng_peak.upper()}_ts.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06d2e2-4f37-4d3f-93db-c57cfbabbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 8)\n",
    "\n",
    "rg = np.linspace(0.00002, 0.00015, 70)\n",
    "plt.hist(data_ca, label=\"Detector Peak\", bins=rg, histtype=\"step\", linewidth=2.5, color=\"#1f77b4\")  # Blue\n",
    "plt.hist(gan_ca, label=\"Translated Peak\", bins=rg, alpha=0.3, color=\"#ff7f0e\")  # Orange\n",
    "plt.hist(sim_ca, label=\"Simulated Peak\", bins=rg, histtype=\"step\", linewidth=2.5, color=\"#2ca02c\")  # Green\n",
    "\n",
    "plt.xlabel(\"Current Amplitude\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"# of Events\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "# plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks()  # Bigger tick labels\n",
    "plt.yticks()  # Bigger tick labels\n",
    "plt.minorticks_on()\n",
    "plt.savefig(f\"figs/{eng_peak.upper()}_amp.pdf\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"IoU between Detector Peak and Simulated Peak: {calculate_iou(data_ca, sim_ca, rg, normed=False):.10f}\")\n",
    "print(f\"IoU between Detector Peak and Translated Peak: {calculate_iou(data_ca, gan_ca, rg, normed=False):.10f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856e119-8d97-42c8-9bc6-87450716b763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433b717-53ce-4a7c-9b90-7c5c698524a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cb8a0-7dab-4055-9733-306cef29223f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
